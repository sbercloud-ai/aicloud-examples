{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b670114",
   "metadata": {},
   "source": [
    "# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465f9b94-c4f9-4c5b-85fe-ed97ec601be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir: /home/jovyan/aicloud-examples/lightning-example\n"
     ]
    }
   ],
   "source": [
    "import client_lib\n",
    "import pathlib\n",
    "\n",
    "BASE_DIR = pathlib.Path().absolute()\n",
    "print(f\"Working dir: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a8c4a8-9c76-45f7-a4ce-b7f01462c68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> region   </span>â”ƒ<span style=\"font-weight: bold\"> instance_type                </span>â”ƒ<span style=\"font-weight: bold\"> memory </span>â”ƒ<span style=\"font-weight: bold\"> cpu   </span>â”ƒ<span style=\"font-weight: bold\"> gpu </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”©\n",
       "â”‚ A100-MT  â”‚ free.0gpu                    â”‚ 3Gi    â”‚ 0.5   â”‚ 0   â”‚\n",
       "â”‚ A100-MT  â”‚ cpu.8C.32G                   â”‚ 31Gi   â”‚ 7.5   â”‚ 0   â”‚\n",
       "â”‚ A100-MT  â”‚ cpu.12C.48G                  â”‚ 47Gi   â”‚ 11.5  â”‚ 0   â”‚\n",
       "â”‚ A100-MT  â”‚ cpu.16C.64G                  â”‚ 57Gi   â”‚ 15.5  â”‚ 0   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.1gpu                    â”‚ 243Gi  â”‚ 16.0  â”‚ 1   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.2gpu                    â”‚ 486Gi  â”‚ 32.0  â”‚ 2   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.3gpu                    â”‚ 729Gi  â”‚ 48.0  â”‚ 3   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.4gpu                    â”‚ 972Gi  â”‚ 64.0  â”‚ 4   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.5gpu                    â”‚ 1215Gi â”‚ 80.0  â”‚ 5   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.6gpu                    â”‚ 1458Gi â”‚ 96.0  â”‚ 6   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.7gpu                    â”‚ 1701Gi â”‚ 112.0 â”‚ 7   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.8gpu                    â”‚ 1944Gi â”‚ 128.0 â”‚ 8   â”‚\n",
       "â”‚ SR004    â”‚ free.0gpu                    â”‚ 3Gi    â”‚ 0.5   â”‚ 0   â”‚\n",
       "â”‚ SR004    â”‚ cpu.8C.32G                   â”‚ 31Gi   â”‚ 7.5   â”‚ 0   â”‚\n",
       "â”‚ SR004    â”‚ cpu.12C.48G                  â”‚ 47Gi   â”‚ 11.5  â”‚ 0   â”‚\n",
       "â”‚ SR004    â”‚ cpu.16C.64G                  â”‚ 57Gi   â”‚ 15.5  â”‚ 0   â”‚\n",
       "â”‚ SR004    â”‚ a100.1gpu                    â”‚ 243Gi  â”‚ 16.0  â”‚ 1   â”‚\n",
       "â”‚ SR004    â”‚ a100.2gpu                    â”‚ 486Gi  â”‚ 32.0  â”‚ 2   â”‚\n",
       "â”‚ SR004    â”‚ a100.3gpu                    â”‚ 729Gi  â”‚ 48.0  â”‚ 3   â”‚\n",
       "â”‚ SR004    â”‚ a100.4gpu                    â”‚ 972Gi  â”‚ 64.0  â”‚ 4   â”‚\n",
       "â”‚ SR004    â”‚ a100.5gpu                    â”‚ 1215Gi â”‚ 80.0  â”‚ 5   â”‚\n",
       "â”‚ SR004    â”‚ a100.6gpu                    â”‚ 1458Gi â”‚ 96.0  â”‚ 6   â”‚\n",
       "â”‚ SR004    â”‚ a100.7gpu                    â”‚ 1701Gi â”‚ 112.0 â”‚ 7   â”‚\n",
       "â”‚ SR004    â”‚ a100.8gpu                    â”‚ 1944Gi â”‚ 128.0 â”‚ 8   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.1gpu.80vG.12C.96G   â”‚ 96Gi   â”‚ 12.0  â”‚ 1   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.1gpu.80vG.12C.182G  â”‚ 182Gi  â”‚ 12.0  â”‚ 1   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.2gpu.80vG.24C.192G  â”‚ 192Gi  â”‚ 24.0  â”‚ 2   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.2gpu.80vG.24C.364G  â”‚ 364Gi  â”‚ 24.0  â”‚ 2   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.3gpu.80vG.36C.546G  â”‚ 546Gi  â”‚ 36.0  â”‚ 3   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.3gpu.80vG.36C.288G  â”‚ 288Gi  â”‚ 36.0  â”‚ 3   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.4gpu.80vG.48C.384G  â”‚ 384Gi  â”‚ 48.0  â”‚ 4   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.4gpu.80vG.48C.728G  â”‚ 728Gi  â”‚ 48.0  â”‚ 4   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.5gpu.80vG.60C.910G  â”‚ 910Gi  â”‚ 60.0  â”‚ 5   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.5gpu.80vG.60C.480G  â”‚ 480Gi  â”‚ 60.0  â”‚ 5   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.6gpu.80vG.72C.1092G â”‚ 1092Gi â”‚ 72.0  â”‚ 6   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.6gpu.80vG.72C.576G  â”‚ 576Gi  â”‚ 72.0  â”‚ 6   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.7gpu.80vG.84C.672G  â”‚ 672Gi  â”‚ 84.0  â”‚ 7   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.7gpu.80vG.84C.1274G â”‚ 1274Gi â”‚ 84.0  â”‚ 7   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.8gpu.80vG.96C.768G  â”‚ 768Gi  â”‚ 96.0  â”‚ 8   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.8gpu.80vG.96C.1456G â”‚ 1456Gi â”‚ 96.0  â”‚ 8   â”‚\n",
       "â”‚ SR006    â”‚ free.0gpu                    â”‚ 3Gi    â”‚ 0.5   â”‚ 0   â”‚\n",
       "â”‚ SR006    â”‚ v100.1gpu                    â”‚ 92Gi   â”‚ 3.0   â”‚ 1   â”‚\n",
       "â”‚ SR006    â”‚ cpu.8C.32G                   â”‚ 31Gi   â”‚ 7.5   â”‚ 0   â”‚\n",
       "â”‚ SR006    â”‚ v100.2gpu                    â”‚ 184Gi  â”‚ 6.0   â”‚ 2   â”‚\n",
       "â”‚ SR006    â”‚ v100.3gpu                    â”‚ 276Gi  â”‚ 9.0   â”‚ 3   â”‚\n",
       "â”‚ SR006    â”‚ cpu.12C.48G                  â”‚ 47Gi   â”‚ 11.5  â”‚ 0   â”‚\n",
       "â”‚ SR006    â”‚ v100.4gpu                    â”‚ 368Gi  â”‚ 12.0  â”‚ 4   â”‚\n",
       "â”‚ SR006    â”‚ cpu.16C.64G                  â”‚ 57Gi   â”‚ 15.5  â”‚ 0   â”‚\n",
       "â”‚ SR006    â”‚ v100.5gpu                    â”‚ 460Gi  â”‚ 15.0  â”‚ 5   â”‚\n",
       "â”‚ SR006    â”‚ v100.6gpu                    â”‚ 552Gi  â”‚ 18.0  â”‚ 6   â”‚\n",
       "â”‚ SR006    â”‚ v100.7gpu                    â”‚ 644Gi  â”‚ 21.0  â”‚ 7   â”‚\n",
       "â”‚ SR006    â”‚ v100.8gpu                    â”‚ 736Gi  â”‚ 24.0  â”‚ 8   â”‚\n",
       "â”‚ SR006    â”‚ v100.9gpu                    â”‚ 828Gi  â”‚ 27.0  â”‚ 9   â”‚\n",
       "â”‚ SR006    â”‚ v100.10gpu                   â”‚ 920Gi  â”‚ 30.0  â”‚ 10  â”‚\n",
       "â”‚ SR006    â”‚ v100.11gpu                   â”‚ 1012Gi â”‚ 33.0  â”‚ 11  â”‚\n",
       "â”‚ SR006    â”‚ v100.12gpu                   â”‚ 1104Gi â”‚ 36.0  â”‚ 12  â”‚\n",
       "â”‚ SR006    â”‚ v100.13gpu                   â”‚ 1196Gi â”‚ 39.0  â”‚ 13  â”‚\n",
       "â”‚ SR006    â”‚ v100.14gpu                   â”‚ 1288Gi â”‚ 42.0  â”‚ 14  â”‚\n",
       "â”‚ SR006    â”‚ v100.15gpu                   â”‚ 1380Gi â”‚ 45.0  â”‚ 15  â”‚\n",
       "â”‚ SR006    â”‚ v100.16gpu                   â”‚ 1472Gi â”‚ 48.0  â”‚ 16  â”‚\n",
       "â”‚ SR006    â”‚ a100plus.1gpu.80vG.12C.244G  â”‚ 244Gi  â”‚ 12.0  â”‚ 1   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.1gpu.80vG.12C.96G   â”‚ 96Gi   â”‚ 12.0  â”‚ 1   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.2gpu.80vG.24C.488G  â”‚ 488Gi  â”‚ 24.0  â”‚ 2   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.2gpu.80vG.24C.192G  â”‚ 192Gi  â”‚ 24.0  â”‚ 2   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.3gpu.80vG.36C.288G  â”‚ 288Gi  â”‚ 36.0  â”‚ 3   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.3gpu.80vG.36C.732G  â”‚ 732Gi  â”‚ 36.0  â”‚ 3   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.4gpu.80vG.48C.384G  â”‚ 384Gi  â”‚ 48.0  â”‚ 4   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.4gpu.80vG.48C.976G  â”‚ 976Gi  â”‚ 48.0  â”‚ 4   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.5gpu.80vG.60C.1220G â”‚ 1220Gi â”‚ 60.0  â”‚ 5   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.5gpu.80vG.60C.480G  â”‚ 480Gi  â”‚ 60.0  â”‚ 5   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.6gpu.80vG.72C.576G  â”‚ 576Gi  â”‚ 72.0  â”‚ 6   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.6gpu.80vG.72C.1464G â”‚ 1464Gi â”‚ 72.0  â”‚ 6   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.7gpu.80vG.84C.672G  â”‚ 672Gi  â”‚ 84.0  â”‚ 7   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.7gpu.80vG.84C.1708G â”‚ 1708Gi â”‚ 84.0  â”‚ 7   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.8gpu.80vG.96C.768G  â”‚ 768Gi  â”‚ 96.0  â”‚ 8   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.8gpu.80vG.96C.1952G â”‚ 1952Gi â”‚ 96.0  â”‚ 8   â”‚\n",
       "â”‚ DGX2-MT  â”‚ free.0gpu                    â”‚ 3Gi    â”‚ 0.5   â”‚ 0   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.1gpu                    â”‚ 92Gi   â”‚ 3.0   â”‚ 1   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.2gpu                    â”‚ 184Gi  â”‚ 6.0   â”‚ 2   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.3gpu                    â”‚ 276Gi  â”‚ 9.0   â”‚ 3   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.4gpu                    â”‚ 368Gi  â”‚ 12.0  â”‚ 4   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.5gpu                    â”‚ 460Gi  â”‚ 15.0  â”‚ 5   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.6gpu                    â”‚ 552Gi  â”‚ 18.0  â”‚ 6   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.7gpu                    â”‚ 644Gi  â”‚ 21.0  â”‚ 7   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.8gpu                    â”‚ 736Gi  â”‚ 24.0  â”‚ 8   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.9gpu                    â”‚ 828Gi  â”‚ 27.0  â”‚ 9   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.10gpu                   â”‚ 920Gi  â”‚ 30.0  â”‚ 10  â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.11gpu                   â”‚ 1012Gi â”‚ 33.0  â”‚ 11  â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.12gpu                   â”‚ 1104Gi â”‚ 36.0  â”‚ 12  â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.13gpu                   â”‚ 1196Gi â”‚ 39.0  â”‚ 13  â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.14gpu                   â”‚ 1288Gi â”‚ 42.0  â”‚ 14  â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.15gpu                   â”‚ 1380Gi â”‚ 45.0  â”‚ 15  â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.16gpu                   â”‚ 1472Gi â”‚ 48.0  â”‚ 16  â”‚\n",
       "â”‚ SR002-MT â”‚ free.0gpu                    â”‚ 3Gi    â”‚ 0.5   â”‚ 0   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.1gpu.40                 â”‚ 230Gi  â”‚ 12.0  â”‚ 1   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.2gpu.40                 â”‚ 460Gi  â”‚ 24.0  â”‚ 2   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.3gpu.40                 â”‚ 690Gi  â”‚ 36.0  â”‚ 3   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.4gpu.40                 â”‚ 920Gi  â”‚ 48.0  â”‚ 4   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.1gpu.80vG.12C.96G       â”‚ 80Gi   â”‚ 10.0  â”‚ 1   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.2gpu.80vG.24C.192G      â”‚ 160Gi  â”‚ 20.0  â”‚ 2   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.3gpu.80vG.36C.288G      â”‚ 240Gi  â”‚ 30.0  â”‚ 3   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.4gpu.80vG.48C.384G      â”‚ 320Gi  â”‚ 40.0  â”‚ 4   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.5gpu.80vG.60C.480G      â”‚ 400Gi  â”‚ 50.0  â”‚ 5   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.6gpu.80vG.72C.576G      â”‚ 480Gi  â”‚ 60.0  â”‚ 6   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.7gpu.80vG.84C.672G      â”‚ 560Gi  â”‚ 70.0  â”‚ 7   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.8gpu.80vG.96C.768G      â”‚ 640Gi  â”‚ 80.0  â”‚ 8   â”‚\n",
       "â”‚ SR003    â”‚ free.0gpu                    â”‚ 3Gi    â”‚ 0.5   â”‚ 0   â”‚\n",
       "â”‚ SR003    â”‚ cpu.2C.8G                    â”‚ 7Gi    â”‚ 1.5   â”‚ 0   â”‚\n",
       "â”‚ SR003    â”‚ cpu.8C.32G                   â”‚ 31Gi   â”‚ 7.5   â”‚ 0   â”‚\n",
       "â”‚ SR003    â”‚ cpu.12C.48G                  â”‚ 47Gi   â”‚ 11.5  â”‚ 0   â”‚\n",
       "â”‚ SR003    â”‚ cpu.16C.64G                  â”‚ 57Gi   â”‚ 15.5  â”‚ 0   â”‚\n",
       "â”‚ SR003    â”‚ a100.1gpu                    â”‚ 243Gi  â”‚ 16.0  â”‚ 1   â”‚\n",
       "â”‚ SR003    â”‚ cpu-ai-2xgiant               â”‚ 128Gi  â”‚ 32.0  â”‚ 0   â”‚\n",
       "â”‚ SR003    â”‚ cpu-ai-3xgiant               â”‚ 192Gi  â”‚ 48.0  â”‚ 0   â”‚\n",
       "â”‚ SR003    â”‚ a100.2gpu                    â”‚ 486Gi  â”‚ 32.0  â”‚ 2   â”‚\n",
       "â”‚ SR003    â”‚ a100.3gpu                    â”‚ 729Gi  â”‚ 48.0  â”‚ 3   â”‚\n",
       "â”‚ SR003    â”‚ a100.4gpu                    â”‚ 972Gi  â”‚ 64.0  â”‚ 4   â”‚\n",
       "â”‚ SR003    â”‚ a100.5gpu                    â”‚ 1215Gi â”‚ 80.0  â”‚ 5   â”‚\n",
       "â”‚ SR003    â”‚ a100.6gpu                    â”‚ 1458Gi â”‚ 96.0  â”‚ 6   â”‚\n",
       "â”‚ SR003    â”‚ a100.7gpu                    â”‚ 1701Gi â”‚ 112.0 â”‚ 7   â”‚\n",
       "â”‚ SR003    â”‚ a100.8gpu                    â”‚ 1944Gi â”‚ 128.0 â”‚ 8   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.1gpu.80vG.12C.182G  â”‚ 182Gi  â”‚ 12.0  â”‚ 1   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.2gpu.80vG.24C.364G  â”‚ 364Gi  â”‚ 24.0  â”‚ 2   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.3gpu.80vG.36C.546G  â”‚ 546Gi  â”‚ 36.0  â”‚ 3   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.4gpu.80vG.48C.728G  â”‚ 728Gi  â”‚ 48.0  â”‚ 4   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.5gpu.80vG.60C.910G  â”‚ 910Gi  â”‚ 60.0  â”‚ 5   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.6gpu.80vG.72C.1092G â”‚ 1092Gi â”‚ 72.0  â”‚ 6   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.7gpu.80vG.84C.1274G â”‚ 1274Gi â”‚ 84.0  â”‚ 7   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.8gpu.80vG.96C.1456G â”‚ 1456Gi â”‚ 96.0  â”‚ 8   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mregion  \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1minstance_type               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mmemory\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mcpu  \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mgpu\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”©\n",
       "â”‚ A100-MT  â”‚ free.0gpu                    â”‚ 3Gi    â”‚ 0.5   â”‚ 0   â”‚\n",
       "â”‚ A100-MT  â”‚ cpu.8C.32G                   â”‚ 31Gi   â”‚ 7.5   â”‚ 0   â”‚\n",
       "â”‚ A100-MT  â”‚ cpu.12C.48G                  â”‚ 47Gi   â”‚ 11.5  â”‚ 0   â”‚\n",
       "â”‚ A100-MT  â”‚ cpu.16C.64G                  â”‚ 57Gi   â”‚ 15.5  â”‚ 0   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.1gpu                    â”‚ 243Gi  â”‚ 16.0  â”‚ 1   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.2gpu                    â”‚ 486Gi  â”‚ 32.0  â”‚ 2   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.3gpu                    â”‚ 729Gi  â”‚ 48.0  â”‚ 3   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.4gpu                    â”‚ 972Gi  â”‚ 64.0  â”‚ 4   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.5gpu                    â”‚ 1215Gi â”‚ 80.0  â”‚ 5   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.6gpu                    â”‚ 1458Gi â”‚ 96.0  â”‚ 6   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.7gpu                    â”‚ 1701Gi â”‚ 112.0 â”‚ 7   â”‚\n",
       "â”‚ A100-MT  â”‚ a100.8gpu                    â”‚ 1944Gi â”‚ 128.0 â”‚ 8   â”‚\n",
       "â”‚ SR004    â”‚ free.0gpu                    â”‚ 3Gi    â”‚ 0.5   â”‚ 0   â”‚\n",
       "â”‚ SR004    â”‚ cpu.8C.32G                   â”‚ 31Gi   â”‚ 7.5   â”‚ 0   â”‚\n",
       "â”‚ SR004    â”‚ cpu.12C.48G                  â”‚ 47Gi   â”‚ 11.5  â”‚ 0   â”‚\n",
       "â”‚ SR004    â”‚ cpu.16C.64G                  â”‚ 57Gi   â”‚ 15.5  â”‚ 0   â”‚\n",
       "â”‚ SR004    â”‚ a100.1gpu                    â”‚ 243Gi  â”‚ 16.0  â”‚ 1   â”‚\n",
       "â”‚ SR004    â”‚ a100.2gpu                    â”‚ 486Gi  â”‚ 32.0  â”‚ 2   â”‚\n",
       "â”‚ SR004    â”‚ a100.3gpu                    â”‚ 729Gi  â”‚ 48.0  â”‚ 3   â”‚\n",
       "â”‚ SR004    â”‚ a100.4gpu                    â”‚ 972Gi  â”‚ 64.0  â”‚ 4   â”‚\n",
       "â”‚ SR004    â”‚ a100.5gpu                    â”‚ 1215Gi â”‚ 80.0  â”‚ 5   â”‚\n",
       "â”‚ SR004    â”‚ a100.6gpu                    â”‚ 1458Gi â”‚ 96.0  â”‚ 6   â”‚\n",
       "â”‚ SR004    â”‚ a100.7gpu                    â”‚ 1701Gi â”‚ 112.0 â”‚ 7   â”‚\n",
       "â”‚ SR004    â”‚ a100.8gpu                    â”‚ 1944Gi â”‚ 128.0 â”‚ 8   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.1gpu.80vG.12C.96G   â”‚ 96Gi   â”‚ 12.0  â”‚ 1   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.1gpu.80vG.12C.182G  â”‚ 182Gi  â”‚ 12.0  â”‚ 1   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.2gpu.80vG.24C.192G  â”‚ 192Gi  â”‚ 24.0  â”‚ 2   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.2gpu.80vG.24C.364G  â”‚ 364Gi  â”‚ 24.0  â”‚ 2   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.3gpu.80vG.36C.546G  â”‚ 546Gi  â”‚ 36.0  â”‚ 3   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.3gpu.80vG.36C.288G  â”‚ 288Gi  â”‚ 36.0  â”‚ 3   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.4gpu.80vG.48C.384G  â”‚ 384Gi  â”‚ 48.0  â”‚ 4   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.4gpu.80vG.48C.728G  â”‚ 728Gi  â”‚ 48.0  â”‚ 4   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.5gpu.80vG.60C.910G  â”‚ 910Gi  â”‚ 60.0  â”‚ 5   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.5gpu.80vG.60C.480G  â”‚ 480Gi  â”‚ 60.0  â”‚ 5   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.6gpu.80vG.72C.1092G â”‚ 1092Gi â”‚ 72.0  â”‚ 6   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.6gpu.80vG.72C.576G  â”‚ 576Gi  â”‚ 72.0  â”‚ 6   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.7gpu.80vG.84C.672G  â”‚ 672Gi  â”‚ 84.0  â”‚ 7   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.7gpu.80vG.84C.1274G â”‚ 1274Gi â”‚ 84.0  â”‚ 7   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.8gpu.80vG.96C.768G  â”‚ 768Gi  â”‚ 96.0  â”‚ 8   â”‚\n",
       "â”‚ SR004    â”‚ a100plus.8gpu.80vG.96C.1456G â”‚ 1456Gi â”‚ 96.0  â”‚ 8   â”‚\n",
       "â”‚ SR006    â”‚ free.0gpu                    â”‚ 3Gi    â”‚ 0.5   â”‚ 0   â”‚\n",
       "â”‚ SR006    â”‚ v100.1gpu                    â”‚ 92Gi   â”‚ 3.0   â”‚ 1   â”‚\n",
       "â”‚ SR006    â”‚ cpu.8C.32G                   â”‚ 31Gi   â”‚ 7.5   â”‚ 0   â”‚\n",
       "â”‚ SR006    â”‚ v100.2gpu                    â”‚ 184Gi  â”‚ 6.0   â”‚ 2   â”‚\n",
       "â”‚ SR006    â”‚ v100.3gpu                    â”‚ 276Gi  â”‚ 9.0   â”‚ 3   â”‚\n",
       "â”‚ SR006    â”‚ cpu.12C.48G                  â”‚ 47Gi   â”‚ 11.5  â”‚ 0   â”‚\n",
       "â”‚ SR006    â”‚ v100.4gpu                    â”‚ 368Gi  â”‚ 12.0  â”‚ 4   â”‚\n",
       "â”‚ SR006    â”‚ cpu.16C.64G                  â”‚ 57Gi   â”‚ 15.5  â”‚ 0   â”‚\n",
       "â”‚ SR006    â”‚ v100.5gpu                    â”‚ 460Gi  â”‚ 15.0  â”‚ 5   â”‚\n",
       "â”‚ SR006    â”‚ v100.6gpu                    â”‚ 552Gi  â”‚ 18.0  â”‚ 6   â”‚\n",
       "â”‚ SR006    â”‚ v100.7gpu                    â”‚ 644Gi  â”‚ 21.0  â”‚ 7   â”‚\n",
       "â”‚ SR006    â”‚ v100.8gpu                    â”‚ 736Gi  â”‚ 24.0  â”‚ 8   â”‚\n",
       "â”‚ SR006    â”‚ v100.9gpu                    â”‚ 828Gi  â”‚ 27.0  â”‚ 9   â”‚\n",
       "â”‚ SR006    â”‚ v100.10gpu                   â”‚ 920Gi  â”‚ 30.0  â”‚ 10  â”‚\n",
       "â”‚ SR006    â”‚ v100.11gpu                   â”‚ 1012Gi â”‚ 33.0  â”‚ 11  â”‚\n",
       "â”‚ SR006    â”‚ v100.12gpu                   â”‚ 1104Gi â”‚ 36.0  â”‚ 12  â”‚\n",
       "â”‚ SR006    â”‚ v100.13gpu                   â”‚ 1196Gi â”‚ 39.0  â”‚ 13  â”‚\n",
       "â”‚ SR006    â”‚ v100.14gpu                   â”‚ 1288Gi â”‚ 42.0  â”‚ 14  â”‚\n",
       "â”‚ SR006    â”‚ v100.15gpu                   â”‚ 1380Gi â”‚ 45.0  â”‚ 15  â”‚\n",
       "â”‚ SR006    â”‚ v100.16gpu                   â”‚ 1472Gi â”‚ 48.0  â”‚ 16  â”‚\n",
       "â”‚ SR006    â”‚ a100plus.1gpu.80vG.12C.244G  â”‚ 244Gi  â”‚ 12.0  â”‚ 1   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.1gpu.80vG.12C.96G   â”‚ 96Gi   â”‚ 12.0  â”‚ 1   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.2gpu.80vG.24C.488G  â”‚ 488Gi  â”‚ 24.0  â”‚ 2   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.2gpu.80vG.24C.192G  â”‚ 192Gi  â”‚ 24.0  â”‚ 2   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.3gpu.80vG.36C.288G  â”‚ 288Gi  â”‚ 36.0  â”‚ 3   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.3gpu.80vG.36C.732G  â”‚ 732Gi  â”‚ 36.0  â”‚ 3   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.4gpu.80vG.48C.384G  â”‚ 384Gi  â”‚ 48.0  â”‚ 4   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.4gpu.80vG.48C.976G  â”‚ 976Gi  â”‚ 48.0  â”‚ 4   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.5gpu.80vG.60C.1220G â”‚ 1220Gi â”‚ 60.0  â”‚ 5   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.5gpu.80vG.60C.480G  â”‚ 480Gi  â”‚ 60.0  â”‚ 5   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.6gpu.80vG.72C.576G  â”‚ 576Gi  â”‚ 72.0  â”‚ 6   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.6gpu.80vG.72C.1464G â”‚ 1464Gi â”‚ 72.0  â”‚ 6   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.7gpu.80vG.84C.672G  â”‚ 672Gi  â”‚ 84.0  â”‚ 7   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.7gpu.80vG.84C.1708G â”‚ 1708Gi â”‚ 84.0  â”‚ 7   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.8gpu.80vG.96C.768G  â”‚ 768Gi  â”‚ 96.0  â”‚ 8   â”‚\n",
       "â”‚ SR006    â”‚ a100plus.8gpu.80vG.96C.1952G â”‚ 1952Gi â”‚ 96.0  â”‚ 8   â”‚\n",
       "â”‚ DGX2-MT  â”‚ free.0gpu                    â”‚ 3Gi    â”‚ 0.5   â”‚ 0   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.1gpu                    â”‚ 92Gi   â”‚ 3.0   â”‚ 1   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.2gpu                    â”‚ 184Gi  â”‚ 6.0   â”‚ 2   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.3gpu                    â”‚ 276Gi  â”‚ 9.0   â”‚ 3   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.4gpu                    â”‚ 368Gi  â”‚ 12.0  â”‚ 4   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.5gpu                    â”‚ 460Gi  â”‚ 15.0  â”‚ 5   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.6gpu                    â”‚ 552Gi  â”‚ 18.0  â”‚ 6   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.7gpu                    â”‚ 644Gi  â”‚ 21.0  â”‚ 7   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.8gpu                    â”‚ 736Gi  â”‚ 24.0  â”‚ 8   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.9gpu                    â”‚ 828Gi  â”‚ 27.0  â”‚ 9   â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.10gpu                   â”‚ 920Gi  â”‚ 30.0  â”‚ 10  â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.11gpu                   â”‚ 1012Gi â”‚ 33.0  â”‚ 11  â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.12gpu                   â”‚ 1104Gi â”‚ 36.0  â”‚ 12  â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.13gpu                   â”‚ 1196Gi â”‚ 39.0  â”‚ 13  â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.14gpu                   â”‚ 1288Gi â”‚ 42.0  â”‚ 14  â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.15gpu                   â”‚ 1380Gi â”‚ 45.0  â”‚ 15  â”‚\n",
       "â”‚ DGX2-MT  â”‚ v100.16gpu                   â”‚ 1472Gi â”‚ 48.0  â”‚ 16  â”‚\n",
       "â”‚ SR002-MT â”‚ free.0gpu                    â”‚ 3Gi    â”‚ 0.5   â”‚ 0   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.1gpu.40                 â”‚ 230Gi  â”‚ 12.0  â”‚ 1   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.2gpu.40                 â”‚ 460Gi  â”‚ 24.0  â”‚ 2   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.3gpu.40                 â”‚ 690Gi  â”‚ 36.0  â”‚ 3   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.4gpu.40                 â”‚ 920Gi  â”‚ 48.0  â”‚ 4   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.1gpu.80vG.12C.96G       â”‚ 80Gi   â”‚ 10.0  â”‚ 1   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.2gpu.80vG.24C.192G      â”‚ 160Gi  â”‚ 20.0  â”‚ 2   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.3gpu.80vG.36C.288G      â”‚ 240Gi  â”‚ 30.0  â”‚ 3   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.4gpu.80vG.48C.384G      â”‚ 320Gi  â”‚ 40.0  â”‚ 4   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.5gpu.80vG.60C.480G      â”‚ 400Gi  â”‚ 50.0  â”‚ 5   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.6gpu.80vG.72C.576G      â”‚ 480Gi  â”‚ 60.0  â”‚ 6   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.7gpu.80vG.84C.672G      â”‚ 560Gi  â”‚ 70.0  â”‚ 7   â”‚\n",
       "â”‚ SR002-MT â”‚ a100.8gpu.80vG.96C.768G      â”‚ 640Gi  â”‚ 80.0  â”‚ 8   â”‚\n",
       "â”‚ SR003    â”‚ free.0gpu                    â”‚ 3Gi    â”‚ 0.5   â”‚ 0   â”‚\n",
       "â”‚ SR003    â”‚ cpu.2C.8G                    â”‚ 7Gi    â”‚ 1.5   â”‚ 0   â”‚\n",
       "â”‚ SR003    â”‚ cpu.8C.32G                   â”‚ 31Gi   â”‚ 7.5   â”‚ 0   â”‚\n",
       "â”‚ SR003    â”‚ cpu.12C.48G                  â”‚ 47Gi   â”‚ 11.5  â”‚ 0   â”‚\n",
       "â”‚ SR003    â”‚ cpu.16C.64G                  â”‚ 57Gi   â”‚ 15.5  â”‚ 0   â”‚\n",
       "â”‚ SR003    â”‚ a100.1gpu                    â”‚ 243Gi  â”‚ 16.0  â”‚ 1   â”‚\n",
       "â”‚ SR003    â”‚ cpu-ai-2xgiant               â”‚ 128Gi  â”‚ 32.0  â”‚ 0   â”‚\n",
       "â”‚ SR003    â”‚ cpu-ai-3xgiant               â”‚ 192Gi  â”‚ 48.0  â”‚ 0   â”‚\n",
       "â”‚ SR003    â”‚ a100.2gpu                    â”‚ 486Gi  â”‚ 32.0  â”‚ 2   â”‚\n",
       "â”‚ SR003    â”‚ a100.3gpu                    â”‚ 729Gi  â”‚ 48.0  â”‚ 3   â”‚\n",
       "â”‚ SR003    â”‚ a100.4gpu                    â”‚ 972Gi  â”‚ 64.0  â”‚ 4   â”‚\n",
       "â”‚ SR003    â”‚ a100.5gpu                    â”‚ 1215Gi â”‚ 80.0  â”‚ 5   â”‚\n",
       "â”‚ SR003    â”‚ a100.6gpu                    â”‚ 1458Gi â”‚ 96.0  â”‚ 6   â”‚\n",
       "â”‚ SR003    â”‚ a100.7gpu                    â”‚ 1701Gi â”‚ 112.0 â”‚ 7   â”‚\n",
       "â”‚ SR003    â”‚ a100.8gpu                    â”‚ 1944Gi â”‚ 128.0 â”‚ 8   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.1gpu.80vG.12C.182G  â”‚ 182Gi  â”‚ 12.0  â”‚ 1   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.2gpu.80vG.24C.364G  â”‚ 364Gi  â”‚ 24.0  â”‚ 2   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.3gpu.80vG.36C.546G  â”‚ 546Gi  â”‚ 36.0  â”‚ 3   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.4gpu.80vG.48C.728G  â”‚ 728Gi  â”‚ 48.0  â”‚ 4   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.5gpu.80vG.60C.910G  â”‚ 910Gi  â”‚ 60.0  â”‚ 5   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.6gpu.80vG.72C.1092G â”‚ 1092Gi â”‚ 72.0  â”‚ 6   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.7gpu.80vG.84C.1274G â”‚ 1274Gi â”‚ 84.0  â”‚ 7   â”‚\n",
       "â”‚ SR003    â”‚ a100plus.8gpu.80vG.96C.1456G â”‚ 1456Gi â”‚ 96.0  â”‚ 8   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_lib.get_instance_types(cluster_type=client_lib.ClusterType('MT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e29d9a7-ebdd-4cc4-82f0-b45efe0b2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"SR002-MT\"\n",
    "INSTANCE_TYPE = \"a100.1gpu.40\"\n",
    "\n",
    "job_run = client_lib.Job(base_image='cr.ai.cloud.ru/76f657c6-f53b-430d-b840-ae7f2c1af48f/job-lightning:0.1',\n",
    "                              script=f'{BASE_DIR}/lightning_image_classification.py',\n",
    "                              region=f'{REGION}',\n",
    "                              instance_type=f'{INSTANCE_TYPE}',\n",
    "                              type=\"pytorch2\",\n",
    "                              n_workers=1,\n",
    "                              pytorch_use_env=True,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbfea1e0-97aa-4640-b176-d51f95f6bc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job \"lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa\" created.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_run.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ca36fe-f25a-47cb-99ab-baa89ee0d704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job status=Running'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_run.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e4fb327-35ea-4146-93b1-5055a6ae848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31T20:28:55.627456293Z Job lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa (pytorch2) is starting...\n",
      "2024-07-31T20:28:55.822994021Z ğŸ•’ Waiting for workers to be ready... ğŸ•’\n",
      "2024-07-31T20:29:10.839119034Z Connecting to mpimaster-0 ..... Ready âœ“\n",
      "2024-07-31T20:29:10.839148844Z ğŸš€ All workers are READY ğŸš€\n",
      "2024-07-31T20:29:12.220421109Z [1,0]<stderr>:/home/user/conda/lib/python3.10/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "2024-07-31T20:29:12.220451445Z [1,0]<stderr>:and will be removed in future. Use torchrun.\n",
      "2024-07-31T20:29:12.220458831Z [1,0]<stderr>:Note that --use-env is set by default in torchrun.\n",
      "2024-07-31T20:29:12.220463795Z [1,0]<stderr>:If your script expects `--local-rank` argument to be set, please\n",
      "2024-07-31T20:29:12.220468430Z [1,0]<stderr>:change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "2024-07-31T20:29:12.220473887Z [1,0]<stderr>:https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "2024-07-31T20:29:12.220478261Z [1,0]<stderr>:further instructions\n",
      "2024-07-31T20:29:12.220482277Z [1,0]<stderr>:\n",
      "2024-07-31T20:29:12.220486222Z [1,0]<stderr>:  warnings.warn(\n",
      "2024-07-31T20:29:19.710232771Z [1,0]<stderr>:\n",
      "Downloading readme:   0%|          | 0.00/2.03k [00:00<?, ?B/s][1,0]<stderr>:\n",
      "Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.03k/2.03k [00:00<00:00, 17.7MB/s]\n",
      "2024-07-31T20:29:22.488733520Z [1,0]<stderr>:\n",
      "Downloading metadata:   0%|          | 0.00/753 [00:00<?, ?B/s][1,0]<stderr>:\n",
      "Downloading metadata: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 753/753 [00:00<00:00, 9.29MB/s]\n",
      "2024-07-31T20:29:32.744281366Z [1,0]<stderr>:\n",
      "Downloading data:   0%|          | 0.00/182M [00:00<?, ?B/s][1,0]<stderr>:\n",
      "Downloading data:   6%|â–Œ         | 10.5M/182M [00:01<00:29, 5.72MB/s][1,0]<stderr>:\n",
      "Downloading data:  12%|â–ˆâ–        | 21.0M/182M [00:02<00:15, 10.6MB/s][1,0]<stderr>:\n",
      "Downloading data:  17%|â–ˆâ–‹        | 31.5M/182M [00:02<00:11, 13.7MB/s][1,0]<stderr>:\n",
      "Downloading data:  23%|â–ˆâ–ˆâ–       | 41.9M/182M [00:03<00:08, 15.8MB/s][1,0]<stderr>:\n",
      "Downloading data:  29%|â–ˆâ–ˆâ–‰       | 52.4M/182M [00:03<00:07, 18.2MB/s][1,0]<stderr>:\n",
      "Downloading data:  35%|â–ˆâ–ˆâ–ˆâ–      | 62.9M/182M [00:04<00:05, 20.9MB/s][1,0]<stderr>:\n",
      "Downloading data:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 73.4M/182M [00:04<00:04, 24.1MB/s][1,0]<stderr>:\n",
      "Downloading data:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 83.9M/182M [00:04<00:03, 25.1MB/s][1,0]<stderr>:\n",
      "Downloading data:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 94.4M/182M [00:05<00:03, 25.7MB/s][1,0]<stderr>:\n",
      "Downloading data:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 105M/182M [00:05<00:03, 23.7MB/s] [1,0]<stderr>:\n",
      "Downloading data:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 115M/182M [00:06<00:03, 21.7MB/s][1,0]<stderr>:\n",
      "Downloading data:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 126M/182M [00:06<00:02, 24.0MB/s][1,0]<stderr>:\n",
      "Downloading data:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 136M/182M [00:07<00:02, 20.8MB/s][1,0]<stderr>:\n",
      "Downloading data:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 147M/182M [00:07<00:01, 22.1MB/s][1,0]<stderr>:\n",
      "Downloading data:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 157M/182M [00:07<00:01, 22.8MB/s][1,0]<stderr>:\n",
      "Downloading data:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 168M/182M [00:08<00:00, 17.6MB/s][1,0]<stderr>:\n",
      "Downloading data:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 178M/182M [00:09<00:00, 18.0MB/s][1,0]<stderr>:\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 182M/182M [00:09<00:00, 17.5MB/s][1,0]<stderr>:\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 182M/182M [00:09<00:00, 18.7MB/s][1,0]<stderr>:\n",
      "2024-07-31T20:29:37.474596621Z [1,0]<stderr>:\n",
      "Downloading data:   0%|          | 0.00/45.8M [00:00<?, ?B/s][1,0]<stderr>:\n",
      "Downloading data:  23%|â–ˆâ–ˆâ–       | 10.5M/45.8M [00:02<00:07, 4.89MB/s][1,0]<stderr>:\n",
      "Downloading data:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21.0M/45.8M [00:02<00:02, 8.75MB/s][1,0]<stderr>:\n",
      "Downloading data:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31.5M/45.8M [00:03<00:01, 12.0MB/s][1,0]<stderr>:\n",
      "Downloading data:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 41.9M/45.8M [00:03<00:00, 14.6MB/s][1,0]<stderr>:\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45.8M/45.8M [00:03<00:00, 15.3MB/s][1,0]<stderr>:\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45.8M/45.8M [00:03<00:00, 11.9MB/s]\n",
      "2024-07-31T20:29:37.884266349Z [1,0]<stderr>:\n",
      "Generating train split:   0%|          | 0/8000 [00:00<?, ? examples/s][1,0]<stderr>:\n",
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8000/8000 [00:00<00:00, 20677.08 examples/s][1,0]<stderr>:\n",
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8000/8000 [00:00<00:00, 19912.16 examples/s]\n",
      "2024-07-31T20:29:37.975466733Z [1,0]<stderr>:\n",
      "Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s][1,0]<stderr>:\n",
      "Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:00<00:00, 22067.27 examples/s]\n",
      "2024-07-31T20:29:38.261968257Z [1,0]<stderr>:Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /home/user/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "2024-07-31T20:29:40.688798856Z [1,0]<stderr>:\n",
      "  0%|          | 0.00/97.8M [00:00<?, ?B/s][1,0]<stderr>:\n",
      "  0%|          | 336k/97.8M [00:00<00:31, 3.20MB/s][1,0]<stderr>:\n",
      "  3%|â–         | 3.30M/97.8M [00:00<00:05, 17.7MB/s][1,0]<stderr>:\n",
      "  9%|â–‰         | 9.09M/97.8M [00:00<00:02, 36.2MB/s][1,0]<stderr>:\n",
      " 14%|â–ˆâ–        | 13.4M/97.8M [00:00<00:02, 35.7MB/s][1,0]<stderr>:\n",
      " 19%|â–ˆâ–‰        | 18.7M/97.8M [00:00<00:02, 40.8MB/s][1,0]<stderr>:\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 24.8M/97.8M [00:00<00:01, 47.5MB/s][1,0]<stderr>:\n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 29.5M/97.8M [00:00<00:01, 45.4MB/s][1,0]<stderr>:\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34.5M/97.8M [00:00<00:01, 46.9MB/s][1,0]<stderr>:\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 39.0M/97.8M [00:01<00:01, 43.1MB/s][1,0]<stderr>:\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 46.1M/97.8M [00:01<00:01, 49.1MB/s][1,0]<stderr>:\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50.9M/97.8M [00:01<00:01, 47.8MB/s][1,0]<stderr>:\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55.5M/97.8M [00:01<00:01, 41.1MB/s][1,0]<stderr>:\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 60.8M/97.8M [00:01<00:00, 44.3MB/s][1,0]<stderr>:\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 65.4M/97.8M [00:01<00:00, 45.3MB/s][1,0]<stderr>:\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 70.0M/97.8M [00:01<00:00, 43.7MB/s][1,0]<stderr>:\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 74.2M/97.8M [00:01<00:00, 43.4MB/s][1,0]<stderr>:\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 78.4M/97.8M [00:01<00:00, 42.7MB/s][1,0]<stderr>:\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 83.0M/97.8M [00:02<00:00, 41.9MB/s][1,0]<stderr>:\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 88.1M/97.8M [00:02<00:00, 45.2MB/s][1,0]<stderr>:\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 95.0M/97.8M [00:02<00:00, 52.7MB/s][1,0]<stderr>:\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:02<00:00, 44.3MB/s]\n",
      "2024-07-31T20:29:40.828172341Z [1,0]<stderr>:GPU available: True (cuda), used: True\n",
      "2024-07-31T20:29:40.828581720Z [1,0]<stderr>:TPU available: False, using: 0 TPU cores\n",
      "2024-07-31T20:29:40.828597674Z [1,0]<stderr>:HPU available: False, using: 0 HPUs\n",
      "2024-07-31T20:29:41.253825730Z [1,0]<stderr>:You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "2024-07-31T20:29:41.253918208Z [1,0]<stderr>:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "2024-07-31T20:29:41.257999695Z [1,0]<stderr>:----------------------------------------------------------------------------------------------------\n",
      "2024-07-31T20:29:41.258016381Z [1,0]<stderr>:distributed_backend=nccl\n",
      "2024-07-31T20:29:41.258021210Z [1,0]<stderr>:All distributed processes registered. Starting with 1 processes\n",
      "2024-07-31T20:29:41.258027114Z [1,0]<stderr>:----------------------------------------------------------------------------------------------------\n",
      "2024-07-31T20:29:41.258043676Z [1,0]<stderr>:\n",
      "2024-07-31T20:29:41.435532576Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:189 [0] NCCL INFO Bootstrap : Using eth0:10.232.32.245<0>\n",
      "2024-07-31T20:29:41.482019155Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:189 [0] NCCL INFO cudaDriverVersion 12030\n",
      "2024-07-31T20:29:41.482037017Z [1,0]<stdout>:NCCL version 2.19.3+cuda12.3\n",
      "2024-07-31T20:29:41.652989909Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so\n",
      "2024-07-31T20:29:41.653007467Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO P2P plugin IBext_v7\n",
      "2024-07-31T20:29:41.858084466Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/IB/SHARP [2]mlx5_4:1/IB/SHARP [3]mlx5_8:1/IB/SHARP [4]mlx5_10:1/IB/SHARP [5]mlx5_12:1/IB/SHARP [6]mlx5_14:1/IB/SHARP [7]mlx5_18:1/IB/SHARP [RO]; OOB eth0:10.232.32.245<0>\n",
      "2024-07-31T20:29:41.858254617Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Using non-device net plugin version 0\n",
      "2024-07-31T20:29:41.858286585Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Using network IBext_v7\n",
      "2024-07-31T20:29:41.860423359Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO comm 0xfcd99a0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId bf000 commId 0xc3c5f378be9b8cca - Init START\n",
      "2024-07-31T20:29:41.932607677Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,ffff0000,00000000\n",
      "2024-07-31T20:29:41.932731529Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 00/32 :    0\n",
      "2024-07-31T20:29:41.932742295Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 01/32 :    0\n",
      "2024-07-31T20:29:41.932748162Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 02/32 :    0\n",
      "2024-07-31T20:29:41.932758812Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 03/32 :    0\n",
      "2024-07-31T20:29:41.932767456Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 04/32 :    0\n",
      "2024-07-31T20:29:41.932771551Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 05/32 :    0\n",
      "2024-07-31T20:29:41.932774825Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 06/32 :    0\n",
      "2024-07-31T20:29:41.932779525Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 07/32 :    0\n",
      "2024-07-31T20:29:41.932783845Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 08/32 :    0\n",
      "2024-07-31T20:29:41.932788126Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 09/32 :    0\n",
      "2024-07-31T20:29:41.932792530Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 10/32 :    0\n",
      "2024-07-31T20:29:41.932795731Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 11/32 :    0\n",
      "2024-07-31T20:29:41.932799326Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 12/32 :    0\n",
      "2024-07-31T20:29:41.932806938Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 13/32 :    0\n",
      "2024-07-31T20:29:41.932822038Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 14/32 :    0\n",
      "2024-07-31T20:29:41.932825470Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 15/32 :    0\n",
      "2024-07-31T20:29:41.932829868Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 16/32 :    0\n",
      "2024-07-31T20:29:41.932833912Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 17/32 :    0\n",
      "2024-07-31T20:29:41.932837159Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 18/32 :    0\n",
      "2024-07-31T20:29:41.932846156Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 19/32 :    0\n",
      "2024-07-31T20:29:41.932849650Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 20/32 :    0\n",
      "2024-07-31T20:29:41.932853210Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 21/32 :    0\n",
      "2024-07-31T20:29:41.932856670Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 22/32 :    0\n",
      "2024-07-31T20:29:41.932860438Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 23/32 :    0\n",
      "2024-07-31T20:29:41.932863588Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 24/32 :    0\n",
      "2024-07-31T20:29:41.932866784Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 25/32 :    0\n",
      "2024-07-31T20:29:41.932870069Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 26/32 :    0\n",
      "2024-07-31T20:29:41.932873412Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 27/32 :    0\n",
      "2024-07-31T20:29:41.932876437Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 28/32 :    0\n",
      "2024-07-31T20:29:41.932879651Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 29/32 :    0\n",
      "2024-07-31T20:29:41.932882678Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 30/32 :    0\n",
      "2024-07-31T20:29:41.932885856Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Channel 31/32 :    0\n",
      "2024-07-31T20:29:41.932896800Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1\n",
      "2024-07-31T20:29:41.932903029Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO P2P Chunksize set to 131072\n",
      "2024-07-31T20:29:41.940732591Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Connected all rings\n",
      "2024-07-31T20:29:41.940749606Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO Connected all trees\n",
      "2024-07-31T20:29:41.940762703Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\n",
      "2024-07-31T20:29:41.956840492Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:524 [0] NCCL INFO comm 0xfcd99a0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId bf000 commId 0xc3c5f378be9b8cca - Init COMPLETE\n",
      "2024-07-31T20:29:42.052766745Z [1,0]<stderr>:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2024-07-31T20:29:42.088798428Z [1,0]<stderr>:\n",
      "2024-07-31T20:29:42.088816206Z [1,0]<stderr>:  | Name  | Type   | Params | Mode \n",
      "2024-07-31T20:29:42.088821681Z [1,0]<stderr>:-----------------------------------------\n",
      "2024-07-31T20:29:42.088826685Z [1,0]<stderr>:0 | model | ResNet | 23.5 M | train\n",
      "2024-07-31T20:29:42.088831321Z [1,0]<stderr>:-----------------------------------------\n",
      "2024-07-31T20:29:42.088836626Z [1,0]<stderr>:23.5 M    Trainable params\n",
      "2024-07-31T20:29:42.088841695Z [1,0]<stderr>:0         Non-trainable params\n",
      "2024-07-31T20:29:42.088845647Z [1,0]<stderr>:23.5 M    Total params\n",
      "2024-07-31T20:29:42.088848848Z [1,0]<stderr>:94.049    Total estimated model params size (MB)\n",
      "2024-07-31T20:29:46.380462371Z [1,0]<stderr>:/home/user/conda/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (32) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "2024-07-31T20:29:50.889575813Z [1,0]<stdout>:\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s][1,0]<stdout>:\n",
      "Sanity Checking:   0% 0/2 [00:00<?, ?it/s]        [1,0]<stdout>:\n",
      "Sanity Checking DataLoader 0:   0% 0/2 [00:00<?, ?it/s][1,0]<stdout>:\n",
      "Sanity Checking DataLoader 0:  50% 1/2 [00:00<00:00,  2.93it/s][1,0]<stdout>:\n",
      "Sanity Checking DataLoader 0: 100% 2/2 [00:00<00:00,  5.74it/s][1,0]<stdout>:\n",
      "                                                               \n",
      "[1,0]<stdout>:\n",
      "Training: |          | 0/? [00:00<?, ?it/s]\n",
      "Training:   0% 0/32 [00:00<?, ?it/s]       \n",
      "Epoch 0:   0% 0/32 [00:00<?, ?it/s] [1,0]<stdout>:\n",
      "Epoch 0:   3% 1/32 [00:01<00:38,  1.23s/it][1,0]<stdout>:\n",
      "Epoch 0:   3% 1/32 [00:01<00:38,  1.24s/it, v_num=3, train_loss_step=0.698][1,0]<stdout>:\n",
      "Epoch 0:   6% 2/32 [00:01<00:18,  1.59it/s, v_num=3, train_loss_step=0.698][1,0]<stdout>:\n",
      "Epoch 0:   6% 2/32 [00:01<00:18,  1.58it/s, v_num=3, train_loss_step=0.564][1,0]<stdout>:\n",
      "Epoch 0:   9% 3/32 [00:01<00:12,  2.31it/s, v_num=3, train_loss_step=0.564][1,0]<stdout>:\n",
      "Epoch 0:   9% 3/32 [00:01<00:12,  2.30it/s, v_num=3, train_loss_step=0.506][1,0]<stdout>:\n",
      "Epoch 0:  12% 4/32 [00:01<00:09,  3.01it/s, v_num=3, train_loss_step=0.506][1,0]<stdout>:\n",
      "Epoch 0:  12% 4/32 [00:01<00:09,  3.00it/s, v_num=3, train_loss_step=0.348][1,0]<stdout>:\n",
      "Epoch 0:  16% 5/32 [00:01<00:07,  3.69it/s, v_num=3, train_loss_step=0.348][1,0]<stdout>:\n",
      "Epoch 0:  16% 5/32 [00:01<00:07,  3.68it/s, v_num=3, train_loss_step=0.338][1,0]<stdout>:\n",
      "Epoch 0:  19% 6/32 [00:01<00:06,  4.30it/s, v_num=3, train_loss_step=0.338][1,0]<stdout>:\n",
      "Epoch 0:  19% 6/32 [00:01<00:06,  4.30it/s, v_num=3, train_loss_step=0.330][1,0]<stdout>:\n",
      "Epoch 0:  22% 7/32 [00:01<00:05,  4.93it/s, v_num=3, train_loss_step=0.330][1,0]<stdout>:\n",
      "Epoch 0:  22% 7/32 [00:01<00:05,  4.92it/s, v_num=3, train_loss_step=0.324][1,0]<stdout>:\n",
      "Epoch 0:  25% 8/32 [00:01<00:04,  5.53it/s, v_num=3, train_loss_step=0.324][1,0]<stdout>:\n",
      "Epoch 0:  25% 8/32 [00:01<00:04,  5.52it/s, v_num=3, train_loss_step=0.339][1,0]<stdout>:\n",
      "Epoch 0:  28% 9/32 [00:01<00:03,  6.10it/s, v_num=3, train_loss_step=0.339][1,0]<stdout>:\n",
      "Epoch 0:  28% 9/32 [00:01<00:03,  6.09it/s, v_num=3, train_loss_step=0.348][1,0]<stdout>:\n",
      "Epoch 0:  31% 10/32 [00:01<00:03,  6.64it/s, v_num=3, train_loss_step=0.348][1,0]<stdout>:\n",
      "Epoch 0:  31% 10/32 [00:01<00:03,  6.63it/s, v_num=3, train_loss_step=0.263][1,0]<stdout>:\n",
      "Epoch 0:  34% 11/32 [00:01<00:02,  7.17it/s, v_num=3, train_loss_step=0.263][1,0]<stdout>:\n",
      "Epoch 0:  34% 11/32 [00:01<00:02,  7.16it/s, v_num=3, train_loss_step=0.242][1,0]<stdout>:\n",
      "Epoch 0:  38% 12/32 [00:01<00:02,  7.69it/s, v_num=3, train_loss_step=0.242][1,0]<stdout>:\n",
      "Epoch 0:  38% 12/32 [00:01<00:02,  7.67it/s, v_num=3, train_loss_step=0.308][1,0]<stdout>:\n",
      "Epoch 0:  41% 13/32 [00:01<00:02,  7.45it/s, v_num=3, train_loss_step=0.308][1,0]<stdout>:\n",
      "Epoch 0:  41% 13/32 [00:01<00:02,  7.43it/s, v_num=3, train_loss_step=0.274][1,0]<stdout>:\n",
      "Epoch 0:  44% 14/32 [00:01<00:02,  7.89it/s, v_num=3, train_loss_step=0.274][1,0]<stdout>:\n",
      "Epoch 0:  44% 14/32 [00:01<00:02,  7.87it/s, v_num=3, train_loss_step=0.226][1,0]<stdout>:\n",
      "Epoch 0:  47% 15/32 [00:01<00:02,  8.32it/s, v_num=3, train_loss_step=0.226][1,0]<stdout>:\n",
      "Epoch 0:  47% 15/32 [00:01<00:02,  8.30it/s, v_num=3, train_loss_step=0.272][1,0]<stdout>:\n",
      "Epoch 0:  50% 16/32 [00:01<00:01,  8.74it/s, v_num=3, train_loss_step=0.272][1,0]<stdout>:\n",
      "Epoch 0:  50% 16/32 [00:01<00:01,  8.72it/s, v_num=3, train_loss_step=0.202][1,0]<stdout>:\n",
      "Epoch 0:  53% 17/32 [00:01<00:01,  9.15it/s, v_num=3, train_loss_step=0.202][1,0]<stdout>:\n",
      "Epoch 0:  53% 17/32 [00:01<00:01,  9.13it/s, v_num=3, train_loss_step=0.190][1,0]<stdout>:\n",
      "Epoch 0:  56% 18/32 [00:01<00:01,  9.54it/s, v_num=3, train_loss_step=0.190][1,0]<stdout>:\n",
      "Epoch 0:  56% 18/32 [00:01<00:01,  9.52it/s, v_num=3, train_loss_step=0.212][1,0]<stdout>:\n",
      "Epoch 0:  59% 19/32 [00:01<00:01,  9.93it/s, v_num=3, train_loss_step=0.212][1,0]<stdout>:\n",
      "Epoch 0:  59% 19/32 [00:01<00:01,  9.91it/s, v_num=3, train_loss_step=0.194][1,0]<stdout>:\n",
      "Epoch 0:  62% 20/32 [00:01<00:01, 10.29it/s, v_num=3, train_loss_step=0.194][1,0]<stdout>:\n",
      "Epoch 0:  62% 20/32 [00:01<00:01, 10.28it/s, v_num=3, train_loss_step=0.190][1,0]<stdout>:\n",
      "Epoch 0:  66% 21/32 [00:01<00:01, 10.65it/s, v_num=3, train_loss_step=0.190][1,0]<stdout>:\n",
      "Epoch 0:  66% 21/32 [00:01<00:01, 10.63it/s, v_num=3, train_loss_step=0.220][1,0]<stdout>:\n",
      "Epoch 0:  69% 22/32 [00:02<00:00, 10.99it/s, v_num=3, train_loss_step=0.220][1,0]<stdout>:\n",
      "Epoch 0:  69% 22/32 [00:02<00:00, 10.98it/s, v_num=3, train_loss_step=0.179][1,0]<stdout>:\n",
      "Epoch 0:  72% 23/32 [00:02<00:00, 11.34it/s, v_num=3, train_loss_step=0.179][1,0]<stdout>:\n",
      "Epoch 0:  72% 23/32 [00:02<00:00, 11.32it/s, v_num=3, train_loss_step=0.196][1,0]<stdout>:\n",
      "Epoch 0:  75% 24/32 [00:02<00:00, 11.67it/s, v_num=3, train_loss_step=0.196][1,0]<stdout>:\n",
      "Epoch 0:  75% 24/32 [00:02<00:00, 11.65it/s, v_num=3, train_loss_step=0.166][1,0]<stdout>:\n",
      "Epoch 0:  78% 25/32 [00:02<00:00, 10.27it/s, v_num=3, train_loss_step=0.166][1,0]<stdout>:\n",
      "Epoch 0:  78% 25/32 [00:02<00:00, 10.25it/s, v_num=3, train_loss_step=0.329][1,0]<stdout>:\n",
      "Epoch 0:  81% 26/32 [00:02<00:00, 10.57it/s, v_num=3, train_loss_step=0.329][1,0]<stdout>:\n",
      "Epoch 0:  81% 26/32 [00:02<00:00, 10.55it/s, v_num=3, train_loss_step=0.230][1,0]<stdout>:\n",
      "Epoch 0:  84% 27/32 [00:02<00:00, 10.86it/s, v_num=3, train_loss_step=0.230][1,0]<stdout>:\n",
      "Epoch 0:  84% 27/32 [00:02<00:00, 10.84it/s, v_num=3, train_loss_step=0.177][1,0]<stdout>:\n",
      "Epoch 0:  88% 28/32 [00:02<00:00, 11.15it/s, v_num=3, train_loss_step=0.177][1,0]<stdout>:\n",
      "Epoch 0:  88% 28/32 [00:02<00:00, 11.13it/s, v_num=3, train_loss_step=0.177][1,0]<stdout>:\n",
      "Epoch 0:  91% 29/32 [00:02<00:00, 11.43it/s, v_num=3, train_loss_step=0.177][1,0]<stdout>:\n",
      "Epoch 0:  91% 29/32 [00:02<00:00, 11.41it/s, v_num=3, train_loss_step=0.179][1,0]<stdout>:\n",
      "Epoch 0:  94% 30/32 [00:02<00:00, 11.70it/s, v_num=3, train_loss_step=0.179][1,0]<stdout>:\n",
      "Epoch 0:  94% 30/32 [00:02<00:00, 11.68it/s, v_num=3, train_loss_step=0.194][1,0]<stdout>:\n",
      "Epoch 0:  97% 31/32 [00:02<00:00, 11.97it/s, v_num=3, train_loss_step=0.194][1,0]<stdout>:\n",
      "Epoch 0:  97% 31/32 [00:02<00:00, 11.95it/s, v_num=3, train_loss_step=0.195][1,0]<stdout>:\n",
      "Epoch 0: 100% 32/32 [00:02<00:00, 11.63it/s, v_num=3, train_loss_step=0.195][1,0]<stdout>:\n",
      "Epoch 0: 100% 32/32 [00:02<00:00, 11.63it/s, v_num=3, train_loss_step=0.202][1,0]<stdout>:\n",
      "2024-07-31T20:29:51.595849639Z [1,0]<stdout>:\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:51.595884120Z [1,0]<stdout>:\n",
      "Validation:   0% 0/8 [00:00<?, ?it/s]        \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:51.604309895Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:51.613648505Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  12% 1/8 [00:00<00:00, 115.86it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:51.623763429Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  25% 2/8 [00:00<00:00, 111.24it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:51.634321870Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  38% 3/8 [00:00<00:00, 106.80it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:51.644506328Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  50% 4/8 [00:00<00:00, 103.46it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:51.654715870Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  62% 5/8 [00:00<00:00, 102.40it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:51.665077059Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  75% 6/8 [00:00<00:00, 101.62it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:51.724141769Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  88% 7/8 [00:00<00:00, 100.86it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:51.728414897Z [1,0]<stdout>:\n",
      "Validation DataLoader 0: 100% 8/8 [00:00<00:00, 62.28it/s] \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:58.400141686Z [1,0]<stdout>:\n",
      "                                                          [1,0]<stdout>:\u001b[A[1,0]<stdout>:\n",
      "Epoch 0: 100% 32/32 [00:05<00:00,  5.98it/s, v_num=3, train_loss_step=0.202, val_loss=0.250][1,0]<stdout>:\n",
      "Epoch 0: 100% 32/32 [00:05<00:00,  5.98it/s, v_num=3, train_loss_step=0.202, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 0:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.202, val_loss=0.250, train_loss_epoch=0.277]         [1,0]<stdout>:\n",
      "Epoch 1:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.202, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:   3% 1/32 [00:02<01:19,  2.57s/it, v_num=3, train_loss_step=0.202, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:   3% 1/32 [00:02<01:19,  2.57s/it, v_num=3, train_loss_step=0.125, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:   6% 2/32 [00:02<00:40,  1.34s/it, v_num=3, train_loss_step=0.125, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:   6% 2/32 [00:02<00:40,  1.34s/it, v_num=3, train_loss_step=0.0854, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:   9% 3/32 [00:02<00:26,  1.11it/s, v_num=3, train_loss_step=0.0854, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:   9% 3/32 [00:02<00:26,  1.11it/s, v_num=3, train_loss_step=0.0873, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  12% 4/32 [00:02<00:19,  1.46it/s, v_num=3, train_loss_step=0.0873, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  12% 4/32 [00:02<00:19,  1.46it/s, v_num=3, train_loss_step=0.0941, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  16% 5/32 [00:02<00:14,  1.80it/s, v_num=3, train_loss_step=0.0941, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  16% 5/32 [00:02<00:15,  1.80it/s, v_num=3, train_loss_step=0.0819, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  19% 6/32 [00:02<00:12,  2.14it/s, v_num=3, train_loss_step=0.0819, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  19% 6/32 [00:02<00:12,  2.14it/s, v_num=3, train_loss_step=0.0871, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  22% 7/32 [00:02<00:10,  2.47it/s, v_num=3, train_loss_step=0.0871, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  22% 7/32 [00:02<00:10,  2.47it/s, v_num=3, train_loss_step=0.0883, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  25% 8/32 [00:02<00:08,  2.78it/s, v_num=3, train_loss_step=0.0883, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  25% 8/32 [00:02<00:08,  2.78it/s, v_num=3, train_loss_step=0.0865, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  28% 9/32 [00:02<00:07,  3.10it/s, v_num=3, train_loss_step=0.0865, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  28% 9/32 [00:02<00:07,  3.10it/s, v_num=3, train_loss_step=0.0618, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  31% 10/32 [00:02<00:06,  3.41it/s, v_num=3, train_loss_step=0.0618, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  31% 10/32 [00:02<00:06,  3.41it/s, v_num=3, train_loss_step=0.0768, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  34% 11/32 [00:02<00:05,  3.71it/s, v_num=3, train_loss_step=0.0768, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  34% 11/32 [00:02<00:05,  3.71it/s, v_num=3, train_loss_step=0.0873, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  38% 12/32 [00:02<00:04,  4.01it/s, v_num=3, train_loss_step=0.0873, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  38% 12/32 [00:02<00:04,  4.01it/s, v_num=3, train_loss_step=0.0666, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  41% 13/32 [00:03<00:04,  4.01it/s, v_num=3, train_loss_step=0.0666, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  41% 13/32 [00:03<00:04,  4.00it/s, v_num=3, train_loss_step=0.0676, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  44% 14/32 [00:03<00:04,  4.09it/s, v_num=3, train_loss_step=0.0676, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  44% 14/32 [00:03<00:04,  4.08it/s, v_num=3, train_loss_step=0.0515, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  47% 15/32 [00:03<00:03,  4.34it/s, v_num=3, train_loss_step=0.0515, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  47% 15/32 [00:03<00:03,  4.34it/s, v_num=3, train_loss_step=0.0587, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  50% 16/32 [00:03<00:03,  4.60it/s, v_num=3, train_loss_step=0.0587, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  50% 16/32 [00:03<00:03,  4.59it/s, v_num=3, train_loss_step=0.0512, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  53% 17/32 [00:03<00:03,  4.84it/s, v_num=3, train_loss_step=0.0512, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  53% 17/32 [00:03<00:03,  4.84it/s, v_num=3, train_loss_step=0.0649, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  56% 18/32 [00:03<00:02,  5.09it/s, v_num=3, train_loss_step=0.0649, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  56% 18/32 [00:03<00:02,  5.08it/s, v_num=3, train_loss_step=0.0649, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  59% 19/32 [00:03<00:02,  5.32it/s, v_num=3, train_loss_step=0.0649, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  59% 19/32 [00:03<00:02,  5.32it/s, v_num=3, train_loss_step=0.0826, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  62% 20/32 [00:03<00:02,  5.56it/s, v_num=3, train_loss_step=0.0826, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  62% 20/32 [00:03<00:02,  5.55it/s, v_num=3, train_loss_step=0.0574, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  66% 21/32 [00:03<00:01,  5.79it/s, v_num=3, train_loss_step=0.0574, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  66% 21/32 [00:03<00:01,  5.79it/s, v_num=3, train_loss_step=0.0632, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  69% 22/32 [00:03<00:01,  6.02it/s, v_num=3, train_loss_step=0.0632, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  69% 22/32 [00:03<00:01,  6.02it/s, v_num=3, train_loss_step=0.0637, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  72% 23/32 [00:03<00:01,  6.25it/s, v_num=3, train_loss_step=0.0637, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  72% 23/32 [00:03<00:01,  6.24it/s, v_num=3, train_loss_step=0.0395, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  75% 24/32 [00:03<00:01,  6.47it/s, v_num=3, train_loss_step=0.0395, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  75% 24/32 [00:03<00:01,  6.47it/s, v_num=3, train_loss_step=0.0485, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  78% 25/32 [00:03<00:01,  6.47it/s, v_num=3, train_loss_step=0.0485, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  78% 25/32 [00:03<00:01,  6.47it/s, v_num=3, train_loss_step=0.0406, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  81% 26/32 [00:04<00:00,  6.39it/s, v_num=3, train_loss_step=0.0406, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  81% 26/32 [00:04<00:00,  6.39it/s, v_num=3, train_loss_step=0.0242, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  84% 27/32 [00:04<00:00,  6.59it/s, v_num=3, train_loss_step=0.0242, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  84% 27/32 [00:04<00:00,  6.59it/s, v_num=3, train_loss_step=0.0583, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  88% 28/32 [00:04<00:00,  6.79it/s, v_num=3, train_loss_step=0.0583, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  88% 28/32 [00:04<00:00,  6.79it/s, v_num=3, train_loss_step=0.0558, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  91% 29/32 [00:04<00:00,  6.99it/s, v_num=3, train_loss_step=0.0558, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  91% 29/32 [00:04<00:00,  6.99it/s, v_num=3, train_loss_step=0.0805, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  94% 30/32 [00:04<00:00,  7.19it/s, v_num=3, train_loss_step=0.0805, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  94% 30/32 [00:04<00:00,  7.18it/s, v_num=3, train_loss_step=0.0954, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  97% 31/32 [00:04<00:00,  7.38it/s, v_num=3, train_loss_step=0.0954, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1:  97% 31/32 [00:04<00:00,  7.37it/s, v_num=3, train_loss_step=0.0472, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1: 100% 32/32 [00:04<00:00,  7.58it/s, v_num=3, train_loss_step=0.0472, val_loss=0.250, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1: 100% 32/32 [00:04<00:00,  7.58it/s, v_num=3, train_loss_step=0.107, val_loss=0.250, train_loss_epoch=0.277] [1,0]<stdout>:\n",
      "2024-07-31T20:29:59.106062466Z [1,0]<stdout>:\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:59.106190605Z [1,0]<stdout>:\n",
      "Validation:   0% 0/8 [00:00<?, ?it/s]        \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:59.114795798Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:59.123991765Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  12% 1/8 [00:00<00:00, 112.90it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:59.134129701Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  25% 2/8 [00:00<00:00, 110.79it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:59.144541501Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  38% 3/8 [00:00<00:00, 106.43it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:59.154888746Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  50% 4/8 [00:00<00:00, 103.61it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:59.165459529Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  62% 5/8 [00:00<00:00, 102.13it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:59.175899760Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  75% 6/8 [00:00<00:00, 100.79it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:59.186246793Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  88% 7/8 [00:00<00:00, 100.05it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:29:59.193113188Z [1,0]<stdout>:\n",
      "Validation DataLoader 0: 100% 8/8 [00:00<00:00, 99.61it/s] \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:05.993586025Z [1,0]<stdout>:\n",
      "                                                          \u001b[A[1,0]<stdout>:\n",
      "Epoch 1: 100% 32/32 [00:06<00:00,  4.65it/s, v_num=3, train_loss_step=0.107, val_loss=0.176, train_loss_epoch=0.277][1,0]<stdout>:\n",
      "Epoch 1: 100% 32/32 [00:06<00:00,  4.65it/s, v_num=3, train_loss_step=0.107, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 1:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.107, val_loss=0.176, train_loss_epoch=0.0695]         [1,0]<stdout>:\n",
      "Epoch 2:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.107, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:   3% 1/32 [00:02<01:23,  2.69s/it, v_num=3, train_loss_step=0.107, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:   3% 1/32 [00:02<01:23,  2.69s/it, v_num=3, train_loss_step=0.0325, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:   6% 2/32 [00:02<00:40,  1.36s/it, v_num=3, train_loss_step=0.0325, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:   6% 2/32 [00:02<00:40,  1.36s/it, v_num=3, train_loss_step=0.0291, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:   9% 3/32 [00:02<00:26,  1.09it/s, v_num=3, train_loss_step=0.0291, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:   9% 3/32 [00:02<00:26,  1.09it/s, v_num=3, train_loss_step=0.0204, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  12% 4/32 [00:02<00:19,  1.43it/s, v_num=3, train_loss_step=0.0204, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  12% 4/32 [00:02<00:19,  1.43it/s, v_num=3, train_loss_step=0.031, val_loss=0.176, train_loss_epoch=0.0695] [1,0]<stdout>:\n",
      "Epoch 2:  16% 5/32 [00:02<00:15,  1.77it/s, v_num=3, train_loss_step=0.031, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  16% 5/32 [00:02<00:15,  1.77it/s, v_num=3, train_loss_step=0.0204, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  19% 6/32 [00:02<00:12,  2.11it/s, v_num=3, train_loss_step=0.0204, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  19% 6/32 [00:02<00:12,  2.10it/s, v_num=3, train_loss_step=0.0261, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  22% 7/32 [00:02<00:10,  2.42it/s, v_num=3, train_loss_step=0.0261, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  22% 7/32 [00:02<00:10,  2.42it/s, v_num=3, train_loss_step=0.0292, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  25% 8/32 [00:02<00:08,  2.74it/s, v_num=3, train_loss_step=0.0292, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  25% 8/32 [00:02<00:08,  2.74it/s, v_num=3, train_loss_step=0.0264, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  28% 9/32 [00:02<00:07,  3.06it/s, v_num=3, train_loss_step=0.0264, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  28% 9/32 [00:02<00:07,  3.05it/s, v_num=3, train_loss_step=0.013, val_loss=0.176, train_loss_epoch=0.0695] [1,0]<stdout>:\n",
      "Epoch 2:  31% 10/32 [00:02<00:06,  3.36it/s, v_num=3, train_loss_step=0.013, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  31% 10/32 [00:02<00:06,  3.35it/s, v_num=3, train_loss_step=0.0374, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  34% 11/32 [00:03<00:05,  3.66it/s, v_num=3, train_loss_step=0.0374, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  34% 11/32 [00:03<00:05,  3.66it/s, v_num=3, train_loss_step=0.0371, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  38% 12/32 [00:03<00:05,  3.95it/s, v_num=3, train_loss_step=0.0371, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  38% 12/32 [00:03<00:05,  3.95it/s, v_num=3, train_loss_step=0.0125, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  41% 13/32 [00:03<00:04,  3.82it/s, v_num=3, train_loss_step=0.0125, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  41% 13/32 [00:03<00:04,  3.82it/s, v_num=3, train_loss_step=0.030, val_loss=0.176, train_loss_epoch=0.0695] [1,0]<stdout>:\n",
      "Epoch 2:  44% 14/32 [00:03<00:04,  4.01it/s, v_num=3, train_loss_step=0.030, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  44% 14/32 [00:03<00:04,  4.01it/s, v_num=3, train_loss_step=0.0284, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  47% 15/32 [00:03<00:03,  4.27it/s, v_num=3, train_loss_step=0.0284, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  47% 15/32 [00:03<00:03,  4.26it/s, v_num=3, train_loss_step=0.0319, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  50% 16/32 [00:03<00:03,  4.51it/s, v_num=3, train_loss_step=0.0319, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  50% 16/32 [00:03<00:03,  4.51it/s, v_num=3, train_loss_step=0.0188, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  53% 17/32 [00:03<00:03,  4.76it/s, v_num=3, train_loss_step=0.0188, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  53% 17/32 [00:03<00:03,  4.76it/s, v_num=3, train_loss_step=0.0373, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  56% 18/32 [00:03<00:02,  5.00it/s, v_num=3, train_loss_step=0.0373, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  56% 18/32 [00:03<00:02,  5.00it/s, v_num=3, train_loss_step=0.0524, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  59% 19/32 [00:03<00:02,  5.24it/s, v_num=3, train_loss_step=0.0524, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  59% 19/32 [00:03<00:02,  5.23it/s, v_num=3, train_loss_step=0.0148, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  62% 20/32 [00:03<00:02,  5.47it/s, v_num=3, train_loss_step=0.0148, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  62% 20/32 [00:03<00:02,  5.47it/s, v_num=3, train_loss_step=0.017, val_loss=0.176, train_loss_epoch=0.0695] [1,0]<stdout>:\n",
      "Epoch 2:  66% 21/32 [00:03<00:01,  5.70it/s, v_num=3, train_loss_step=0.017, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  66% 21/32 [00:03<00:01,  5.69it/s, v_num=3, train_loss_step=0.027, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  69% 22/32 [00:03<00:01,  5.92it/s, v_num=3, train_loss_step=0.027, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  69% 22/32 [00:03<00:01,  5.92it/s, v_num=3, train_loss_step=0.0138, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  72% 23/32 [00:03<00:01,  6.14it/s, v_num=3, train_loss_step=0.0138, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  72% 23/32 [00:03<00:01,  6.14it/s, v_num=3, train_loss_step=0.0295, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  75% 24/32 [00:03<00:01,  6.36it/s, v_num=3, train_loss_step=0.0295, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  75% 24/32 [00:03<00:01,  6.36it/s, v_num=3, train_loss_step=0.0277, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  78% 25/32 [00:04<00:01,  6.11it/s, v_num=3, train_loss_step=0.0277, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  78% 25/32 [00:04<00:01,  6.11it/s, v_num=3, train_loss_step=0.040, val_loss=0.176, train_loss_epoch=0.0695] [1,0]<stdout>:\n",
      "Epoch 2:  81% 26/32 [00:04<00:00,  6.17it/s, v_num=3, train_loss_step=0.040, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  81% 26/32 [00:04<00:00,  6.16it/s, v_num=3, train_loss_step=0.0182, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  84% 27/32 [00:04<00:00,  6.37it/s, v_num=3, train_loss_step=0.0182, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  84% 27/32 [00:04<00:00,  6.36it/s, v_num=3, train_loss_step=0.0237, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  88% 28/32 [00:04<00:00,  6.56it/s, v_num=3, train_loss_step=0.0237, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  88% 28/32 [00:04<00:00,  6.55it/s, v_num=3, train_loss_step=0.0412, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  91% 29/32 [00:04<00:00,  6.75it/s, v_num=3, train_loss_step=0.0412, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  91% 29/32 [00:04<00:00,  6.75it/s, v_num=3, train_loss_step=0.0301, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  94% 30/32 [00:04<00:00,  6.94it/s, v_num=3, train_loss_step=0.0301, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  94% 30/32 [00:04<00:00,  6.94it/s, v_num=3, train_loss_step=0.0251, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  97% 31/32 [00:04<00:00,  7.13it/s, v_num=3, train_loss_step=0.0251, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2:  97% 31/32 [00:04<00:00,  7.12it/s, v_num=3, train_loss_step=0.0156, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2: 100% 32/32 [00:04<00:00,  7.32it/s, v_num=3, train_loss_step=0.0156, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2: 100% 32/32 [00:04<00:00,  7.32it/s, v_num=3, train_loss_step=0.0753, val_loss=0.176, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "2024-07-31T20:30:06.755228164Z [1,0]<stdout>:\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:06.755386693Z [1,0]<stdout>:\n",
      "Validation:   0% 0/8 [00:00<?, ?it/s]        \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:06.763809014Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:06.772764172Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  12% 1/8 [00:00<00:00, 115.39it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:06.783189485Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  25% 2/8 [00:00<00:00, 113.49it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:06.793520697Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  38% 3/8 [00:00<00:00, 106.96it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:06.803902922Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  50% 4/8 [00:00<00:00, 104.23it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:06.814227323Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  62% 5/8 [00:00<00:00, 102.55it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:06.824470737Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  75% 6/8 [00:00<00:00, 101.57it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:06.834743591Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  88% 7/8 [00:00<00:00, 100.97it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:06.842410588Z [1,0]<stdout>:\n",
      "Validation DataLoader 0: 100% 8/8 [00:00<00:00, 100.50it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:13.497902412Z [1,0]<stdout>:\n",
      "                                                           [1,0]<stdout>:\u001b[A[1,0]<stdout>:\n",
      "Epoch 2: 100% 32/32 [00:07<00:00,  4.54it/s, v_num=3, train_loss_step=0.0753, val_loss=0.182, train_loss_epoch=0.0695][1,0]<stdout>:\n",
      "Epoch 2: 100% 32/32 [00:07<00:00,  4.54it/s, v_num=3, train_loss_step=0.0753, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 2:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.0753, val_loss=0.182, train_loss_epoch=0.0274]         [1,0]<stdout>:\n",
      "Epoch 3:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.0753, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:   3% 1/32 [00:02<01:22,  2.68s/it, v_num=3, train_loss_step=0.0753, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:   3% 1/32 [00:02<01:23,  2.68s/it, v_num=3, train_loss_step=0.0212, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:   6% 2/32 [00:02<00:40,  1.35s/it, v_num=3, train_loss_step=0.0212, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:   6% 2/32 [00:02<00:40,  1.35s/it, v_num=3, train_loss_step=0.0245, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:   9% 3/32 [00:02<00:26,  1.10it/s, v_num=3, train_loss_step=0.0245, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:   9% 3/32 [00:02<00:26,  1.10it/s, v_num=3, train_loss_step=0.0437, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  12% 4/32 [00:02<00:19,  1.45it/s, v_num=3, train_loss_step=0.0437, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  12% 4/32 [00:02<00:19,  1.45it/s, v_num=3, train_loss_step=0.0252, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  16% 5/32 [00:02<00:15,  1.79it/s, v_num=3, train_loss_step=0.0252, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  16% 5/32 [00:02<00:15,  1.79it/s, v_num=3, train_loss_step=0.0264, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  19% 6/32 [00:02<00:12,  2.13it/s, v_num=3, train_loss_step=0.0264, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  19% 6/32 [00:02<00:12,  2.12it/s, v_num=3, train_loss_step=0.0154, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  22% 7/32 [00:02<00:10,  2.45it/s, v_num=3, train_loss_step=0.0154, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  22% 7/32 [00:02<00:10,  2.45it/s, v_num=3, train_loss_step=0.0276, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  25% 8/32 [00:02<00:08,  2.78it/s, v_num=3, train_loss_step=0.0276, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  25% 8/32 [00:02<00:08,  2.77it/s, v_num=3, train_loss_step=0.0162, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  28% 9/32 [00:02<00:07,  3.09it/s, v_num=3, train_loss_step=0.0162, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  28% 9/32 [00:02<00:07,  3.09it/s, v_num=3, train_loss_step=0.0316, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  31% 10/32 [00:02<00:06,  3.39it/s, v_num=3, train_loss_step=0.0316, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  31% 10/32 [00:02<00:06,  3.39it/s, v_num=3, train_loss_step=0.0137, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  34% 11/32 [00:02<00:05,  3.70it/s, v_num=3, train_loss_step=0.0137, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  34% 11/32 [00:02<00:05,  3.69it/s, v_num=3, train_loss_step=0.0284, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  38% 12/32 [00:03<00:05,  4.00it/s, v_num=3, train_loss_step=0.0284, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  38% 12/32 [00:03<00:05,  3.99it/s, v_num=3, train_loss_step=0.022, val_loss=0.182, train_loss_epoch=0.0274] [1,0]<stdout>:\n",
      "Epoch 3:  41% 13/32 [00:03<00:04,  3.85it/s, v_num=3, train_loss_step=0.022, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  41% 13/32 [00:03<00:04,  3.84it/s, v_num=3, train_loss_step=0.0166, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  44% 14/32 [00:03<00:04,  4.11it/s, v_num=3, train_loss_step=0.0166, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  44% 14/32 [00:03<00:04,  4.10it/s, v_num=3, train_loss_step=0.0231, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  47% 15/32 [00:03<00:03,  4.37it/s, v_num=3, train_loss_step=0.0231, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  47% 15/32 [00:03<00:03,  4.36it/s, v_num=3, train_loss_step=0.0347, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  50% 16/32 [00:03<00:03,  4.62it/s, v_num=3, train_loss_step=0.0347, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  50% 16/32 [00:03<00:03,  4.61it/s, v_num=3, train_loss_step=0.0172, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  53% 17/32 [00:03<00:03,  4.87it/s, v_num=3, train_loss_step=0.0172, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  53% 17/32 [00:03<00:03,  4.86it/s, v_num=3, train_loss_step=0.0249, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  56% 18/32 [00:03<00:02,  5.11it/s, v_num=3, train_loss_step=0.0249, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  56% 18/32 [00:03<00:02,  5.11it/s, v_num=3, train_loss_step=0.0314, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  59% 19/32 [00:03<00:02,  5.36it/s, v_num=3, train_loss_step=0.0314, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  59% 19/32 [00:03<00:02,  5.35it/s, v_num=3, train_loss_step=0.0315, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  62% 20/32 [00:03<00:02,  5.60it/s, v_num=3, train_loss_step=0.0315, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  62% 20/32 [00:03<00:02,  5.59it/s, v_num=3, train_loss_step=0.0296, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  66% 21/32 [00:03<00:01,  5.83it/s, v_num=3, train_loss_step=0.0296, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  66% 21/32 [00:03<00:01,  5.82it/s, v_num=3, train_loss_step=0.0149, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  69% 22/32 [00:03<00:01,  6.06it/s, v_num=3, train_loss_step=0.0149, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  69% 22/32 [00:03<00:01,  6.06it/s, v_num=3, train_loss_step=0.0229, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  72% 23/32 [00:03<00:01,  6.29it/s, v_num=3, train_loss_step=0.0229, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  72% 23/32 [00:03<00:01,  6.28it/s, v_num=3, train_loss_step=0.0161, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  75% 24/32 [00:03<00:01,  6.52it/s, v_num=3, train_loss_step=0.0161, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  75% 24/32 [00:03<00:01,  6.51it/s, v_num=3, train_loss_step=0.0105, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  78% 25/32 [00:04<00:01,  6.16it/s, v_num=3, train_loss_step=0.0105, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  78% 25/32 [00:04<00:01,  6.15it/s, v_num=3, train_loss_step=0.0475, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  81% 26/32 [00:04<00:00,  6.36it/s, v_num=3, train_loss_step=0.0475, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  81% 26/32 [00:04<00:00,  6.35it/s, v_num=3, train_loss_step=0.0246, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  84% 27/32 [00:04<00:00,  6.56it/s, v_num=3, train_loss_step=0.0246, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  84% 27/32 [00:04<00:00,  6.56it/s, v_num=3, train_loss_step=0.0348, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  88% 28/32 [00:04<00:00,  6.76it/s, v_num=3, train_loss_step=0.0348, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  88% 28/32 [00:04<00:00,  6.75it/s, v_num=3, train_loss_step=0.0236, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  91% 29/32 [00:04<00:00,  6.96it/s, v_num=3, train_loss_step=0.0236, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  91% 29/32 [00:04<00:00,  6.95it/s, v_num=3, train_loss_step=0.0114, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  94% 30/32 [00:04<00:00,  7.15it/s, v_num=3, train_loss_step=0.0114, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  94% 30/32 [00:04<00:00,  7.15it/s, v_num=3, train_loss_step=0.0208, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  97% 31/32 [00:04<00:00,  7.35it/s, v_num=3, train_loss_step=0.0208, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3:  97% 31/32 [00:04<00:00,  7.34it/s, v_num=3, train_loss_step=0.0182, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3: 100% 32/32 [00:04<00:00,  7.54it/s, v_num=3, train_loss_step=0.0182, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3: 100% 32/32 [00:04<00:00,  7.54it/s, v_num=3, train_loss_step=0.0474, val_loss=0.182, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "2024-07-31T20:30:14.188179466Z [1,0]<stdout>:\n",
      "Validation: |          | 0/? [00:00<?, ?it/s][1,0]<stdout>:\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:14.188357394Z [1,0]<stdout>:\n",
      "Validation:   0% 0/8 [00:00<?, ?it/s]        \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:14.197544634Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:14.207141390Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  12% 1/8 [00:00<00:00, 105.58it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:14.217375388Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  25% 2/8 [00:00<00:00, 104.89it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:14.227625249Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  38% 3/8 [00:00<00:00, 102.41it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:14.237977454Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  50% 4/8 [00:00<00:00, 101.34it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:14.248325085Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  62% 5/8 [00:00<00:00, 100.27it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:14.258755383Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  75% 6/8 [00:00<00:00, 99.61it/s] \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:14.269173011Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  88% 7/8 [00:00<00:00, 99.06it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:14.276223595Z [1,0]<stdout>:\n",
      "Validation DataLoader 0: 100% 8/8 [00:00<00:00, 98.66it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:21.011829716Z [1,0]<stdout>:\n",
      "                                                          [1,0]<stdout>:\u001b[A[1,0]<stdout>:\n",
      "Epoch 3: 100% 32/32 [00:06<00:00,  4.68it/s, v_num=3, train_loss_step=0.0474, val_loss=0.188, train_loss_epoch=0.0274][1,0]<stdout>:\n",
      "Epoch 3: 100% 32/32 [00:06<00:00,  4.68it/s, v_num=3, train_loss_step=0.0474, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 3:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.0474, val_loss=0.188, train_loss_epoch=0.0244]         [1,0]<stdout>:\n",
      "Epoch 4:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.0474, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:   3% 1/32 [00:02<01:22,  2.66s/it, v_num=3, train_loss_step=0.0474, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:   3% 1/32 [00:02<01:22,  2.66s/it, v_num=3, train_loss_step=0.0254, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:   6% 2/32 [00:02<00:40,  1.34s/it, v_num=3, train_loss_step=0.0254, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:   6% 2/32 [00:02<00:40,  1.34s/it, v_num=3, train_loss_step=0.0231, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:   9% 3/32 [00:02<00:26,  1.10it/s, v_num=3, train_loss_step=0.0231, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:   9% 3/32 [00:02<00:26,  1.10it/s, v_num=3, train_loss_step=0.0317, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  12% 4/32 [00:02<00:19,  1.46it/s, v_num=3, train_loss_step=0.0317, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  12% 4/32 [00:02<00:19,  1.46it/s, v_num=3, train_loss_step=0.0321, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  16% 5/32 [00:02<00:15,  1.80it/s, v_num=3, train_loss_step=0.0321, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  16% 5/32 [00:02<00:15,  1.80it/s, v_num=3, train_loss_step=0.0318, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  19% 6/32 [00:02<00:12,  2.14it/s, v_num=3, train_loss_step=0.0318, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  19% 6/32 [00:02<00:12,  2.13it/s, v_num=3, train_loss_step=0.0276, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  22% 7/32 [00:02<00:10,  2.47it/s, v_num=3, train_loss_step=0.0276, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  22% 7/32 [00:02<00:10,  2.46it/s, v_num=3, train_loss_step=0.0249, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  25% 8/32 [00:02<00:08,  2.79it/s, v_num=3, train_loss_step=0.0249, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  25% 8/32 [00:02<00:08,  2.79it/s, v_num=3, train_loss_step=0.0222, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  28% 9/32 [00:02<00:07,  3.11it/s, v_num=3, train_loss_step=0.0222, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  28% 9/32 [00:02<00:07,  3.10it/s, v_num=3, train_loss_step=0.0197, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  31% 10/32 [00:02<00:06,  3.42it/s, v_num=3, train_loss_step=0.0197, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  31% 10/32 [00:02<00:06,  3.42it/s, v_num=3, train_loss_step=0.0306, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  34% 11/32 [00:02<00:05,  3.73it/s, v_num=3, train_loss_step=0.0306, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  34% 11/32 [00:02<00:05,  3.72it/s, v_num=3, train_loss_step=0.0269, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  38% 12/32 [00:02<00:04,  4.03it/s, v_num=3, train_loss_step=0.0269, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  38% 12/32 [00:02<00:04,  4.02it/s, v_num=3, train_loss_step=0.0171, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  41% 13/32 [00:03<00:04,  3.80it/s, v_num=3, train_loss_step=0.0171, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  41% 13/32 [00:03<00:05,  3.80it/s, v_num=3, train_loss_step=0.0199, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  44% 14/32 [00:03<00:04,  4.06it/s, v_num=3, train_loss_step=0.0199, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  44% 14/32 [00:03<00:04,  4.06it/s, v_num=3, train_loss_step=0.0263, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  47% 15/32 [00:03<00:03,  4.32it/s, v_num=3, train_loss_step=0.0263, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  47% 15/32 [00:03<00:03,  4.31it/s, v_num=3, train_loss_step=0.0188, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  50% 16/32 [00:03<00:03,  4.57it/s, v_num=3, train_loss_step=0.0188, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  50% 16/32 [00:03<00:03,  4.56it/s, v_num=3, train_loss_step=0.0184, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  53% 17/32 [00:03<00:03,  4.82it/s, v_num=3, train_loss_step=0.0184, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  53% 17/32 [00:03<00:03,  4.81it/s, v_num=3, train_loss_step=0.0235, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  56% 18/32 [00:03<00:02,  5.06it/s, v_num=3, train_loss_step=0.0235, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  56% 18/32 [00:03<00:02,  5.05it/s, v_num=3, train_loss_step=0.0219, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  59% 19/32 [00:03<00:02,  5.29it/s, v_num=3, train_loss_step=0.0219, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  59% 19/32 [00:03<00:02,  5.29it/s, v_num=3, train_loss_step=0.0135, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  62% 20/32 [00:03<00:02,  5.53it/s, v_num=3, train_loss_step=0.0135, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  62% 20/32 [00:03<00:02,  5.53it/s, v_num=3, train_loss_step=0.0319, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  66% 21/32 [00:03<00:01,  5.76it/s, v_num=3, train_loss_step=0.0319, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  66% 21/32 [00:03<00:01,  5.76it/s, v_num=3, train_loss_step=0.0164, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  69% 22/32 [00:03<00:01,  5.99it/s, v_num=3, train_loss_step=0.0164, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  69% 22/32 [00:03<00:01,  5.99it/s, v_num=3, train_loss_step=0.0292, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  72% 23/32 [00:03<00:01,  6.21it/s, v_num=3, train_loss_step=0.0292, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  72% 23/32 [00:03<00:01,  6.21it/s, v_num=3, train_loss_step=0.0185, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  75% 24/32 [00:03<00:01,  6.44it/s, v_num=3, train_loss_step=0.0185, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  75% 24/32 [00:03<00:01,  6.43it/s, v_num=3, train_loss_step=0.0203, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  78% 25/32 [00:04<00:01,  6.10it/s, v_num=3, train_loss_step=0.0203, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  78% 25/32 [00:04<00:01,  6.09it/s, v_num=3, train_loss_step=0.0229, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  81% 26/32 [00:04<00:00,  6.30it/s, v_num=3, train_loss_step=0.0229, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  81% 26/32 [00:04<00:00,  6.30it/s, v_num=3, train_loss_step=0.0203, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  84% 27/32 [00:04<00:00,  6.51it/s, v_num=3, train_loss_step=0.0203, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  84% 27/32 [00:04<00:00,  6.50it/s, v_num=3, train_loss_step=0.016, val_loss=0.188, train_loss_epoch=0.0244] [1,0]<stdout>:\n",
      "Epoch 4:  88% 28/32 [00:04<00:00,  6.70it/s, v_num=3, train_loss_step=0.016, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  88% 28/32 [00:04<00:00,  6.70it/s, v_num=3, train_loss_step=0.0184, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  91% 29/32 [00:04<00:00,  6.90it/s, v_num=3, train_loss_step=0.0184, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  91% 29/32 [00:04<00:00,  6.89it/s, v_num=3, train_loss_step=0.0233, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  94% 30/32 [00:04<00:00,  7.10it/s, v_num=3, train_loss_step=0.0233, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  94% 30/32 [00:04<00:00,  7.09it/s, v_num=3, train_loss_step=0.0434, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  97% 31/32 [00:04<00:00,  7.29it/s, v_num=3, train_loss_step=0.0434, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4:  97% 31/32 [00:04<00:00,  7.28it/s, v_num=3, train_loss_step=0.0137, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4: 100% 32/32 [00:04<00:00,  7.48it/s, v_num=3, train_loss_step=0.0137, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4: 100% 32/32 [00:04<00:00,  7.48it/s, v_num=3, train_loss_step=0.0109, val_loss=0.188, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "2024-07-31T20:30:21.642958804Z [1,0]<stdout>:\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:21.643754401Z [1,0]<stdout>:\n",
      "Validation:   0% 0/8 [00:00<?, ?it/s]        \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:21.652612690Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:21.662354974Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  12% 1/8 [00:00<00:00, 101.98it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:21.740301343Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  25% 2/8 [00:00<00:00, 102.02it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:21.764283288Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  38% 3/8 [00:00<00:00, 30.76it/s] \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:21.774226966Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  50% 4/8 [00:00<00:00, 32.91it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:21.784423589Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  62% 5/8 [00:00<00:00, 38.03it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:21.794744489Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  75% 6/8 [00:00<00:00, 42.35it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:21.805009992Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  88% 7/8 [00:00<00:00, 46.05it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:21.811657042Z [1,0]<stdout>:\n",
      "Validation DataLoader 0: 100% 8/8 [00:00<00:00, 49.30it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:28.410746285Z [1,0]<stdout>:\n",
      "                                                          \u001b[A[1,0]<stdout>:\n",
      "Epoch 4: 100% 32/32 [00:06<00:00,  4.61it/s, v_num=3, train_loss_step=0.0109, val_loss=0.189, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 4: 100% 32/32 [00:06<00:00,  4.61it/s, v_num=3, train_loss_step=0.0109, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 4:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.0109, val_loss=0.189, train_loss_epoch=0.0234]         [1,0]<stdout>:\n",
      "Epoch 5:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.0109, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:   3% 1/32 [00:02<01:20,  2.61s/it, v_num=3, train_loss_step=0.0109, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:   3% 1/32 [00:02<01:20,  2.61s/it, v_num=3, train_loss_step=0.0218, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:   6% 2/32 [00:02<00:39,  1.32s/it, v_num=3, train_loss_step=0.0218, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:   6% 2/32 [00:02<00:39,  1.32s/it, v_num=3, train_loss_step=0.0287, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:   9% 3/32 [00:02<00:25,  1.12it/s, v_num=3, train_loss_step=0.0287, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:   9% 3/32 [00:02<00:25,  1.12it/s, v_num=3, train_loss_step=0.0222, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  12% 4/32 [00:02<00:18,  1.48it/s, v_num=3, train_loss_step=0.0222, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  12% 4/32 [00:02<00:18,  1.47it/s, v_num=3, train_loss_step=0.0236, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  16% 5/32 [00:02<00:14,  1.83it/s, v_num=3, train_loss_step=0.0236, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  16% 5/32 [00:02<00:14,  1.82it/s, v_num=3, train_loss_step=0.0216, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  19% 6/32 [00:02<00:12,  2.16it/s, v_num=3, train_loss_step=0.0216, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  19% 6/32 [00:02<00:12,  2.16it/s, v_num=3, train_loss_step=0.0414, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  22% 7/32 [00:02<00:10,  2.50it/s, v_num=3, train_loss_step=0.0414, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  22% 7/32 [00:02<00:10,  2.49it/s, v_num=3, train_loss_step=0.0213, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  25% 8/32 [00:02<00:08,  2.82it/s, v_num=3, train_loss_step=0.0213, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  25% 8/32 [00:02<00:08,  2.82it/s, v_num=3, train_loss_step=0.0217, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  28% 9/32 [00:02<00:07,  3.13it/s, v_num=3, train_loss_step=0.0217, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  28% 9/32 [00:02<00:07,  3.13it/s, v_num=3, train_loss_step=0.0152, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  31% 10/32 [00:02<00:06,  3.45it/s, v_num=3, train_loss_step=0.0152, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  31% 10/32 [00:02<00:06,  3.44it/s, v_num=3, train_loss_step=0.0313, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  34% 11/32 [00:02<00:05,  3.75it/s, v_num=3, train_loss_step=0.0313, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  34% 11/32 [00:02<00:05,  3.75it/s, v_num=3, train_loss_step=0.0321, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  38% 12/32 [00:02<00:04,  4.06it/s, v_num=3, train_loss_step=0.0321, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  38% 12/32 [00:02<00:04,  4.05it/s, v_num=3, train_loss_step=0.0162, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  41% 13/32 [00:03<00:04,  3.86it/s, v_num=3, train_loss_step=0.0162, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  41% 13/32 [00:03<00:04,  3.86it/s, v_num=3, train_loss_step=0.0272, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  44% 14/32 [00:03<00:04,  4.13it/s, v_num=3, train_loss_step=0.0272, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  44% 14/32 [00:03<00:04,  4.12it/s, v_num=3, train_loss_step=0.0203, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  47% 15/32 [00:03<00:03,  4.38it/s, v_num=3, train_loss_step=0.0203, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  47% 15/32 [00:03<00:03,  4.38it/s, v_num=3, train_loss_step=0.0154, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  50% 16/32 [00:03<00:03,  4.64it/s, v_num=3, train_loss_step=0.0154, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  50% 16/32 [00:03<00:03,  4.63it/s, v_num=3, train_loss_step=0.0283, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  53% 17/32 [00:03<00:03,  4.89it/s, v_num=3, train_loss_step=0.0283, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  53% 17/32 [00:03<00:03,  4.88it/s, v_num=3, train_loss_step=0.0243, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  56% 18/32 [00:03<00:02,  5.13it/s, v_num=3, train_loss_step=0.0243, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  56% 18/32 [00:03<00:02,  5.13it/s, v_num=3, train_loss_step=0.0192, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  59% 19/32 [00:03<00:02,  5.37it/s, v_num=3, train_loss_step=0.0192, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  59% 19/32 [00:03<00:02,  5.37it/s, v_num=3, train_loss_step=0.0217, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  62% 20/32 [00:03<00:02,  5.61it/s, v_num=3, train_loss_step=0.0217, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  62% 20/32 [00:03<00:02,  5.61it/s, v_num=3, train_loss_step=0.0418, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  66% 21/32 [00:03<00:01,  5.84it/s, v_num=3, train_loss_step=0.0418, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  66% 21/32 [00:03<00:01,  5.84it/s, v_num=3, train_loss_step=0.0242, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  69% 22/32 [00:03<00:01,  6.07it/s, v_num=3, train_loss_step=0.0242, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  69% 22/32 [00:03<00:01,  6.07it/s, v_num=3, train_loss_step=0.0261, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  72% 23/32 [00:03<00:01,  6.30it/s, v_num=3, train_loss_step=0.0261, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  72% 23/32 [00:03<00:01,  6.29it/s, v_num=3, train_loss_step=0.0255, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  75% 24/32 [00:03<00:01,  6.52it/s, v_num=3, train_loss_step=0.0255, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  75% 24/32 [00:03<00:01,  6.52it/s, v_num=3, train_loss_step=0.0354, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  78% 25/32 [00:04<00:01,  6.20it/s, v_num=3, train_loss_step=0.0354, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  78% 25/32 [00:04<00:01,  6.19it/s, v_num=3, train_loss_step=0.0228, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  81% 26/32 [00:04<00:00,  6.40it/s, v_num=3, train_loss_step=0.0228, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  81% 26/32 [00:04<00:00,  6.39it/s, v_num=3, train_loss_step=0.0184, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  84% 27/32 [00:04<00:00,  6.60it/s, v_num=3, train_loss_step=0.0184, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  84% 27/32 [00:04<00:00,  6.59it/s, v_num=3, train_loss_step=0.0257, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  88% 28/32 [00:04<00:00,  6.80it/s, v_num=3, train_loss_step=0.0257, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  88% 28/32 [00:04<00:00,  6.79it/s, v_num=3, train_loss_step=0.0131, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  91% 29/32 [00:04<00:00,  7.00it/s, v_num=3, train_loss_step=0.0131, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  91% 29/32 [00:04<00:00,  6.99it/s, v_num=3, train_loss_step=0.0149, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  94% 30/32 [00:04<00:00,  7.19it/s, v_num=3, train_loss_step=0.0149, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  94% 30/32 [00:04<00:00,  7.18it/s, v_num=3, train_loss_step=0.0229, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  97% 31/32 [00:04<00:00,  7.38it/s, v_num=3, train_loss_step=0.0229, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5:  97% 31/32 [00:04<00:00,  7.38it/s, v_num=3, train_loss_step=0.0163, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5: 100% 32/32 [00:04<00:00,  7.58it/s, v_num=3, train_loss_step=0.0163, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5: 100% 32/32 [00:04<00:00,  7.58it/s, v_num=3, train_loss_step=0.0429, val_loss=0.189, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "2024-07-31T20:30:29.145949575Z [1,0]<stdout>:\n",
      "Validation: |          | 0/? [00:00<?, ?it/s][1,0]<stdout>:\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:29.146048741Z [1,0]<stdout>:\n",
      "Validation:   0% 0/8 [00:00<?, ?it/s]        \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:29.154528463Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:29.163985333Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  12% 1/8 [00:00<00:00, 114.55it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:29.174228247Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  25% 2/8 [00:00<00:00, 110.03it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:29.184503322Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  38% 3/8 [00:00<00:00, 105.56it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:29.194873063Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  50% 4/8 [00:00<00:00, 103.37it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:29.205217910Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  62% 5/8 [00:00<00:00, 101.90it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:29.215577107Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  75% 6/8 [00:00<00:00, 101.00it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:29.225911705Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  88% 7/8 [00:00<00:00, 100.33it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:29.232503652Z [1,0]<stdout>:\n",
      "Validation DataLoader 0: 100% 8/8 [00:00<00:00, 99.88it/s] \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:36.108584483Z [1,0]<stdout>:\n",
      "                                                          [1,0]<stdout>:\u001b[A[1,0]<stdout>:\n",
      "Epoch 5: 100% 32/32 [00:06<00:00,  4.69it/s, v_num=3, train_loss_step=0.0429, val_loss=0.185, train_loss_epoch=0.0234][1,0]<stdout>:\n",
      "Epoch 5: 100% 32/32 [00:06<00:00,  4.69it/s, v_num=3, train_loss_step=0.0429, val_loss=0.185, train_loss_epoch=0.024] [1,0]<stdout>:\n",
      "Epoch 5:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.0429, val_loss=0.185, train_loss_epoch=0.024]         [1,0]<stdout>:\n",
      "Epoch 6:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.0429, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:   3% 1/32 [00:02<01:25,  2.77s/it, v_num=3, train_loss_step=0.0429, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:   3% 1/32 [00:02<01:25,  2.77s/it, v_num=3, train_loss_step=0.0345, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:   6% 2/32 [00:02<00:42,  1.40s/it, v_num=3, train_loss_step=0.0345, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:   6% 2/32 [00:02<00:42,  1.40s/it, v_num=3, train_loss_step=0.0247, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:   9% 3/32 [00:02<00:27,  1.06it/s, v_num=3, train_loss_step=0.0247, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:   9% 3/32 [00:02<00:27,  1.06it/s, v_num=3, train_loss_step=0.0262, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  12% 4/32 [00:02<00:20,  1.40it/s, v_num=3, train_loss_step=0.0262, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  12% 4/32 [00:02<00:20,  1.40it/s, v_num=3, train_loss_step=0.0147, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  16% 5/32 [00:02<00:15,  1.72it/s, v_num=3, train_loss_step=0.0147, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  16% 5/32 [00:02<00:15,  1.72it/s, v_num=3, train_loss_step=0.0129, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  19% 6/32 [00:02<00:12,  2.04it/s, v_num=3, train_loss_step=0.0129, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  19% 6/32 [00:02<00:12,  2.04it/s, v_num=3, train_loss_step=0.0207, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  22% 7/32 [00:02<00:10,  2.36it/s, v_num=3, train_loss_step=0.0207, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  22% 7/32 [00:02<00:10,  2.36it/s, v_num=3, train_loss_step=0.026, val_loss=0.185, train_loss_epoch=0.024] [1,0]<stdout>:\n",
      "Epoch 6:  25% 8/32 [00:03<00:09,  2.66it/s, v_num=3, train_loss_step=0.026, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  25% 8/32 [00:03<00:09,  2.66it/s, v_num=3, train_loss_step=0.0233, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  28% 9/32 [00:03<00:07,  2.96it/s, v_num=3, train_loss_step=0.0233, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  28% 9/32 [00:03<00:07,  2.96it/s, v_num=3, train_loss_step=0.0165, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  31% 10/32 [00:03<00:06,  3.26it/s, v_num=3, train_loss_step=0.0165, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  31% 10/32 [00:03<00:06,  3.26it/s, v_num=3, train_loss_step=0.0137, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  34% 11/32 [00:03<00:05,  3.55it/s, v_num=3, train_loss_step=0.0137, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  34% 11/32 [00:03<00:05,  3.55it/s, v_num=3, train_loss_step=0.0267, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  38% 12/32 [00:03<00:05,  3.83it/s, v_num=3, train_loss_step=0.0267, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  38% 12/32 [00:03<00:05,  3.83it/s, v_num=3, train_loss_step=0.0187, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  41% 13/32 [00:03<00:05,  3.77it/s, v_num=3, train_loss_step=0.0187, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  41% 13/32 [00:03<00:05,  3.77it/s, v_num=3, train_loss_step=0.0115, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  44% 14/32 [00:03<00:04,  4.02it/s, v_num=3, train_loss_step=0.0115, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  44% 14/32 [00:03<00:04,  4.02it/s, v_num=3, train_loss_step=0.0204, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  47% 15/32 [00:03<00:03,  4.27it/s, v_num=3, train_loss_step=0.0204, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  47% 15/32 [00:03<00:03,  4.27it/s, v_num=3, train_loss_step=0.0205, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  50% 16/32 [00:03<00:03,  4.52it/s, v_num=3, train_loss_step=0.0205, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  50% 16/32 [00:03<00:03,  4.52it/s, v_num=3, train_loss_step=0.0311, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  53% 17/32 [00:03<00:03,  4.77it/s, v_num=3, train_loss_step=0.0311, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  53% 17/32 [00:03<00:03,  4.76it/s, v_num=3, train_loss_step=0.0282, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  56% 18/32 [00:03<00:02,  5.01it/s, v_num=3, train_loss_step=0.0282, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  56% 18/32 [00:03<00:02,  5.00it/s, v_num=3, train_loss_step=0.0383, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  59% 19/32 [00:03<00:02,  5.25it/s, v_num=3, train_loss_step=0.0383, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  59% 19/32 [00:03<00:02,  5.24it/s, v_num=3, train_loss_step=0.029, val_loss=0.185, train_loss_epoch=0.024] [1,0]<stdout>:\n",
      "Epoch 6:  62% 20/32 [00:03<00:02,  5.48it/s, v_num=3, train_loss_step=0.029, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  62% 20/32 [00:03<00:02,  5.48it/s, v_num=3, train_loss_step=0.0174, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  66% 21/32 [00:03<00:01,  5.71it/s, v_num=3, train_loss_step=0.0174, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  66% 21/32 [00:03<00:01,  5.70it/s, v_num=3, train_loss_step=0.0259, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  69% 22/32 [00:03<00:01,  5.94it/s, v_num=3, train_loss_step=0.0259, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  69% 22/32 [00:03<00:01,  5.93it/s, v_num=3, train_loss_step=0.0466, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  72% 23/32 [00:03<00:01,  6.16it/s, v_num=3, train_loss_step=0.0466, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  72% 23/32 [00:03<00:01,  6.16it/s, v_num=3, train_loss_step=0.0156, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  75% 24/32 [00:03<00:01,  6.38it/s, v_num=3, train_loss_step=0.0156, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  75% 24/32 [00:03<00:01,  6.38it/s, v_num=3, train_loss_step=0.0261, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  78% 25/32 [00:04<00:01,  6.06it/s, v_num=3, train_loss_step=0.0261, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  78% 25/32 [00:04<00:01,  6.05it/s, v_num=3, train_loss_step=0.012, val_loss=0.185, train_loss_epoch=0.024] [1,0]<stdout>:\n",
      "Epoch 6:  81% 26/32 [00:04<00:00,  6.26it/s, v_num=3, train_loss_step=0.012, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  81% 26/32 [00:04<00:00,  6.25it/s, v_num=3, train_loss_step=0.0273, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  84% 27/32 [00:04<00:00,  6.46it/s, v_num=3, train_loss_step=0.0273, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  84% 27/32 [00:04<00:00,  6.45it/s, v_num=3, train_loss_step=0.0198, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  88% 28/32 [00:04<00:00,  6.65it/s, v_num=3, train_loss_step=0.0198, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  88% 28/32 [00:04<00:00,  6.65it/s, v_num=3, train_loss_step=0.0244, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  91% 29/32 [00:04<00:00,  6.85it/s, v_num=3, train_loss_step=0.0244, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  91% 29/32 [00:04<00:00,  6.84it/s, v_num=3, train_loss_step=0.0308, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  94% 30/32 [00:04<00:00,  7.04it/s, v_num=3, train_loss_step=0.0308, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  94% 30/32 [00:04<00:00,  7.03it/s, v_num=3, train_loss_step=0.0311, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  97% 31/32 [00:04<00:00,  7.23it/s, v_num=3, train_loss_step=0.0311, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6:  97% 31/32 [00:04<00:00,  7.22it/s, v_num=3, train_loss_step=0.0414, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6: 100% 32/32 [00:04<00:00,  7.42it/s, v_num=3, train_loss_step=0.0414, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6: 100% 32/32 [00:04<00:00,  7.42it/s, v_num=3, train_loss_step=0.0181, val_loss=0.185, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "2024-07-31T20:30:36.860783335Z [1,0]<stdout>:\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:36.860868086Z [1,0]<stdout>:\n",
      "Validation:   0% 0/8 [00:00<?, ?it/s]        \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:36.869285538Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:36.878393785Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  12% 1/8 [00:00<00:00, 115.49it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:36.888743028Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  25% 2/8 [00:00<00:00, 112.62it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:36.898956961Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  38% 3/8 [00:00<00:00, 106.73it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:36.909698600Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  50% 4/8 [00:00<00:00, 104.37it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:36.920057317Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  62% 5/8 [00:00<00:00, 101.91it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:36.930408099Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  75% 6/8 [00:00<00:00, 100.96it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:36.940792691Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  88% 7/8 [00:00<00:00, 100.32it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:36.947456377Z [1,0]<stdout>:\n",
      "Validation DataLoader 0: 100% 8/8 [00:00<00:00, 99.80it/s] \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:43.516601867Z [1,0]<stdout>:\n",
      "                                                          [1,0]<stdout>:\u001b[A[1,0]<stdout>:\n",
      "Epoch 6: 100% 32/32 [00:06<00:00,  4.60it/s, v_num=3, train_loss_step=0.0181, val_loss=0.191, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 6: 100% 32/32 [00:06<00:00,  4.59it/s, v_num=3, train_loss_step=0.0181, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 6:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.0181, val_loss=0.191, train_loss_epoch=0.0243]         [1,0]<stdout>:\n",
      "Epoch 7:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.0181, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:   3% 1/32 [00:02<01:18,  2.52s/it, v_num=3, train_loss_step=0.0181, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:   3% 1/32 [00:02<01:18,  2.53s/it, v_num=3, train_loss_step=0.0278, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:   6% 2/32 [00:02<00:38,  1.28s/it, v_num=3, train_loss_step=0.0278, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:   6% 2/32 [00:02<00:38,  1.28s/it, v_num=3, train_loss_step=0.0275, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:   9% 3/32 [00:02<00:24,  1.16it/s, v_num=3, train_loss_step=0.0275, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:   9% 3/32 [00:02<00:24,  1.16it/s, v_num=3, train_loss_step=0.0308, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  12% 4/32 [00:02<00:18,  1.53it/s, v_num=3, train_loss_step=0.0308, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  12% 4/32 [00:02<00:18,  1.53it/s, v_num=3, train_loss_step=0.0195, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  16% 5/32 [00:02<00:14,  1.89it/s, v_num=3, train_loss_step=0.0195, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  16% 5/32 [00:02<00:14,  1.89it/s, v_num=3, train_loss_step=0.017, val_loss=0.191, train_loss_epoch=0.0243] [1,0]<stdout>:\n",
      "Epoch 7:  19% 6/32 [00:02<00:11,  2.25it/s, v_num=3, train_loss_step=0.017, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  19% 6/32 [00:02<00:11,  2.24it/s, v_num=3, train_loss_step=0.035, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  22% 7/32 [00:02<00:09,  2.58it/s, v_num=3, train_loss_step=0.035, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  22% 7/32 [00:02<00:09,  2.58it/s, v_num=3, train_loss_step=0.0115, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  25% 8/32 [00:02<00:08,  2.93it/s, v_num=3, train_loss_step=0.0115, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  25% 8/32 [00:02<00:08,  2.92it/s, v_num=3, train_loss_step=0.0092, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  28% 9/32 [00:02<00:07,  3.26it/s, v_num=3, train_loss_step=0.0092, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  28% 9/32 [00:02<00:07,  3.25it/s, v_num=3, train_loss_step=0.0183, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  31% 10/32 [00:02<00:06,  3.58it/s, v_num=3, train_loss_step=0.0183, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  31% 10/32 [00:02<00:06,  3.58it/s, v_num=3, train_loss_step=0.029, val_loss=0.191, train_loss_epoch=0.0243] [1,0]<stdout>:\n",
      "Epoch 7:  34% 11/32 [00:02<00:05,  3.89it/s, v_num=3, train_loss_step=0.029, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  34% 11/32 [00:02<00:05,  3.89it/s, v_num=3, train_loss_step=0.0212, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  38% 12/32 [00:02<00:04,  4.20it/s, v_num=3, train_loss_step=0.0212, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  38% 12/32 [00:02<00:04,  4.20it/s, v_num=3, train_loss_step=0.0268, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  41% 13/32 [00:03<00:04,  4.06it/s, v_num=3, train_loss_step=0.0268, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  41% 13/32 [00:03<00:04,  4.06it/s, v_num=3, train_loss_step=0.0252, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  44% 14/32 [00:03<00:04,  4.33it/s, v_num=3, train_loss_step=0.0252, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  44% 14/32 [00:03<00:04,  4.32it/s, v_num=3, train_loss_step=0.016, val_loss=0.191, train_loss_epoch=0.0243] [1,0]<stdout>:\n",
      "Epoch 7:  47% 15/32 [00:03<00:03,  4.60it/s, v_num=3, train_loss_step=0.016, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  47% 15/32 [00:03<00:03,  4.59it/s, v_num=3, train_loss_step=0.0259, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  50% 16/32 [00:03<00:03,  4.86it/s, v_num=3, train_loss_step=0.0259, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  50% 16/32 [00:03<00:03,  4.85it/s, v_num=3, train_loss_step=0.0144, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  53% 17/32 [00:03<00:02,  5.12it/s, v_num=3, train_loss_step=0.0144, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  53% 17/32 [00:03<00:02,  5.11it/s, v_num=3, train_loss_step=0.043, val_loss=0.191, train_loss_epoch=0.0243] [1,0]<stdout>:\n",
      "Epoch 7:  56% 18/32 [00:03<00:02,  5.37it/s, v_num=3, train_loss_step=0.043, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  56% 18/32 [00:03<00:02,  5.37it/s, v_num=3, train_loss_step=0.0283, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  59% 19/32 [00:03<00:02,  5.63it/s, v_num=3, train_loss_step=0.0283, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  59% 19/32 [00:03<00:02,  5.62it/s, v_num=3, train_loss_step=0.0282, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  62% 20/32 [00:03<00:02,  5.88it/s, v_num=3, train_loss_step=0.0282, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  62% 20/32 [00:03<00:02,  5.87it/s, v_num=3, train_loss_step=0.0324, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  66% 21/32 [00:03<00:01,  6.12it/s, v_num=3, train_loss_step=0.0324, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  66% 21/32 [00:03<00:01,  6.11it/s, v_num=3, train_loss_step=0.0267, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  69% 22/32 [00:03<00:01,  6.36it/s, v_num=3, train_loss_step=0.0267, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  69% 22/32 [00:03<00:01,  6.35it/s, v_num=3, train_loss_step=0.0169, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  72% 23/32 [00:03<00:01,  6.60it/s, v_num=3, train_loss_step=0.0169, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  72% 23/32 [00:03<00:01,  6.59it/s, v_num=3, train_loss_step=0.0144, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  75% 24/32 [00:03<00:01,  6.83it/s, v_num=3, train_loss_step=0.0144, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  75% 24/32 [00:03<00:01,  6.83it/s, v_num=3, train_loss_step=0.0267, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  78% 25/32 [00:03<00:01,  6.53it/s, v_num=3, train_loss_step=0.0267, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  78% 25/32 [00:03<00:01,  6.53it/s, v_num=3, train_loss_step=0.032, val_loss=0.191, train_loss_epoch=0.0243] [1,0]<stdout>:\n",
      "Epoch 7:  81% 26/32 [00:03<00:00,  6.68it/s, v_num=3, train_loss_step=0.032, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  81% 26/32 [00:03<00:00,  6.67it/s, v_num=3, train_loss_step=0.0393, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  84% 27/32 [00:03<00:00,  6.88it/s, v_num=3, train_loss_step=0.0393, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  84% 27/32 [00:03<00:00,  6.87it/s, v_num=3, train_loss_step=0.0145, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  88% 28/32 [00:03<00:00,  7.08it/s, v_num=3, train_loss_step=0.0145, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  88% 28/32 [00:03<00:00,  7.07it/s, v_num=3, train_loss_step=0.0255, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  91% 29/32 [00:03<00:00,  7.29it/s, v_num=3, train_loss_step=0.0255, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  91% 29/32 [00:03<00:00,  7.28it/s, v_num=3, train_loss_step=0.0296, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  94% 30/32 [00:04<00:00,  7.49it/s, v_num=3, train_loss_step=0.0296, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  94% 30/32 [00:04<00:00,  7.48it/s, v_num=3, train_loss_step=0.0176, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  97% 31/32 [00:04<00:00,  7.69it/s, v_num=3, train_loss_step=0.0176, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7:  97% 31/32 [00:04<00:00,  7.68it/s, v_num=3, train_loss_step=0.0295, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7: 100% 32/32 [00:04<00:00,  7.89it/s, v_num=3, train_loss_step=0.0295, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7: 100% 32/32 [00:04<00:00,  7.89it/s, v_num=3, train_loss_step=0.0106, val_loss=0.191, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "2024-07-31T20:30:44.235190529Z [1,0]<stdout>:\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:44.235282014Z [1,0]<stdout>:\n",
      "Validation:   0% 0/8 [00:00<?, ?it/s]        \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:44.243932355Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:44.253348315Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  12% 1/8 [00:00<00:00, 112.59it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:44.288430104Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  25% 2/8 [00:00<00:00, 109.29it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:44.299162561Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  38% 3/8 [00:00<00:00, 56.22it/s] \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:44.308999266Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  50% 4/8 [00:00<00:00, 62.42it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:44.319380543Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  62% 5/8 [00:00<00:00, 67.62it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:44.329667335Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  75% 6/8 [00:00<00:00, 71.15it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:44.340020504Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  88% 7/8 [00:00<00:00, 73.99it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:44.346681787Z [1,0]<stdout>:\n",
      "Validation DataLoader 0: 100% 8/8 [00:00<00:00, 76.21it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:51.108332254Z [1,0]<stdout>:\n",
      "                                                          \u001b[A[1,0]<stdout>:\n",
      "Epoch 7: 100% 32/32 [00:06<00:00,  4.72it/s, v_num=3, train_loss_step=0.0106, val_loss=0.185, train_loss_epoch=0.0243][1,0]<stdout>:\n",
      "Epoch 7: 100% 32/32 [00:06<00:00,  4.72it/s, v_num=3, train_loss_step=0.0106, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 7:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.0106, val_loss=0.185, train_loss_epoch=0.0244]         [1,0]<stdout>:\n",
      "Epoch 8:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.0106, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:   3% 1/32 [00:02<01:25,  2.76s/it, v_num=3, train_loss_step=0.0106, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:   3% 1/32 [00:02<01:25,  2.76s/it, v_num=3, train_loss_step=0.0245, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:   6% 2/32 [00:02<00:41,  1.40s/it, v_num=3, train_loss_step=0.0245, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:   6% 2/32 [00:02<00:41,  1.40s/it, v_num=3, train_loss_step=0.0294, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:   9% 3/32 [00:02<00:27,  1.06it/s, v_num=3, train_loss_step=0.0294, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:   9% 3/32 [00:02<00:27,  1.06it/s, v_num=3, train_loss_step=0.0133, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  12% 4/32 [00:02<00:20,  1.40it/s, v_num=3, train_loss_step=0.0133, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  12% 4/32 [00:02<00:20,  1.40it/s, v_num=3, train_loss_step=0.0133, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  16% 5/32 [00:02<00:15,  1.73it/s, v_num=3, train_loss_step=0.0133, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  16% 5/32 [00:02<00:15,  1.73it/s, v_num=3, train_loss_step=0.0166, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  19% 6/32 [00:02<00:12,  2.06it/s, v_num=3, train_loss_step=0.0166, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  19% 6/32 [00:02<00:12,  2.06it/s, v_num=3, train_loss_step=0.0221, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  22% 7/32 [00:02<00:10,  2.38it/s, v_num=3, train_loss_step=0.0221, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  22% 7/32 [00:02<00:10,  2.37it/s, v_num=3, train_loss_step=0.0147, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  25% 8/32 [00:02<00:08,  2.69it/s, v_num=3, train_loss_step=0.0147, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  25% 8/32 [00:02<00:08,  2.69it/s, v_num=3, train_loss_step=0.0242, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  28% 9/32 [00:03<00:07,  2.99it/s, v_num=3, train_loss_step=0.0242, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  28% 9/32 [00:03<00:07,  2.98it/s, v_num=3, train_loss_step=0.0278, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  31% 10/32 [00:03<00:06,  3.29it/s, v_num=3, train_loss_step=0.0278, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  31% 10/32 [00:03<00:06,  3.28it/s, v_num=3, train_loss_step=0.0166, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  34% 11/32 [00:03<00:05,  3.58it/s, v_num=3, train_loss_step=0.0166, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  34% 11/32 [00:03<00:05,  3.58it/s, v_num=3, train_loss_step=0.0222, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  38% 12/32 [00:03<00:05,  3.87it/s, v_num=3, train_loss_step=0.0222, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  38% 12/32 [00:03<00:05,  3.87it/s, v_num=3, train_loss_step=0.0518, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  41% 13/32 [00:03<00:05,  3.78it/s, v_num=3, train_loss_step=0.0518, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  41% 13/32 [00:03<00:05,  3.78it/s, v_num=3, train_loss_step=0.0253, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  44% 14/32 [00:03<00:04,  3.95it/s, v_num=3, train_loss_step=0.0253, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  44% 14/32 [00:03<00:04,  3.95it/s, v_num=3, train_loss_step=0.0273, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  47% 15/32 [00:03<00:04,  4.20it/s, v_num=3, train_loss_step=0.0273, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  47% 15/32 [00:03<00:04,  4.20it/s, v_num=3, train_loss_step=0.0346, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  50% 16/32 [00:03<00:03,  4.45it/s, v_num=3, train_loss_step=0.0346, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  50% 16/32 [00:03<00:03,  4.44it/s, v_num=3, train_loss_step=0.0187, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  53% 17/32 [00:03<00:03,  4.69it/s, v_num=3, train_loss_step=0.0187, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  53% 17/32 [00:03<00:03,  4.68it/s, v_num=3, train_loss_step=0.0432, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  56% 18/32 [00:03<00:02,  4.93it/s, v_num=3, train_loss_step=0.0432, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  56% 18/32 [00:03<00:02,  4.92it/s, v_num=3, train_loss_step=0.0253, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  59% 19/32 [00:03<00:02,  5.16it/s, v_num=3, train_loss_step=0.0253, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  59% 19/32 [00:03<00:02,  5.16it/s, v_num=3, train_loss_step=0.017, val_loss=0.185, train_loss_epoch=0.0244] [1,0]<stdout>:\n",
      "Epoch 8:  62% 20/32 [00:03<00:02,  5.39it/s, v_num=3, train_loss_step=0.017, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  62% 20/32 [00:03<00:02,  5.39it/s, v_num=3, train_loss_step=0.0305, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  66% 21/32 [00:03<00:01,  5.62it/s, v_num=3, train_loss_step=0.0305, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  66% 21/32 [00:03<00:01,  5.62it/s, v_num=3, train_loss_step=0.027, val_loss=0.185, train_loss_epoch=0.0244] [1,0]<stdout>:\n",
      "Epoch 8:  69% 22/32 [00:03<00:01,  5.85it/s, v_num=3, train_loss_step=0.027, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  69% 22/32 [00:03<00:01,  5.84it/s, v_num=3, train_loss_step=0.0267, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  72% 23/32 [00:03<00:01,  6.07it/s, v_num=3, train_loss_step=0.0267, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  72% 23/32 [00:03<00:01,  6.06it/s, v_num=3, train_loss_step=0.0297, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  75% 24/32 [00:03<00:01,  6.29it/s, v_num=3, train_loss_step=0.0297, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  75% 24/32 [00:03<00:01,  6.28it/s, v_num=3, train_loss_step=0.0136, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  78% 25/32 [00:04<00:01,  6.09it/s, v_num=3, train_loss_step=0.0136, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  78% 25/32 [00:04<00:01,  6.08it/s, v_num=3, train_loss_step=0.0241, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  81% 26/32 [00:04<00:00,  6.20it/s, v_num=3, train_loss_step=0.0241, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  81% 26/32 [00:04<00:00,  6.20it/s, v_num=3, train_loss_step=0.0212, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  84% 27/32 [00:04<00:00,  6.40it/s, v_num=3, train_loss_step=0.0212, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  84% 27/32 [00:04<00:00,  6.40it/s, v_num=3, train_loss_step=0.0224, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  88% 28/32 [00:04<00:00,  6.60it/s, v_num=3, train_loss_step=0.0224, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  88% 28/32 [00:04<00:00,  6.59it/s, v_num=3, train_loss_step=0.0184, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  91% 29/32 [00:04<00:00,  6.79it/s, v_num=3, train_loss_step=0.0184, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  91% 29/32 [00:04<00:00,  6.79it/s, v_num=3, train_loss_step=0.0148, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  94% 30/32 [00:04<00:00,  6.98it/s, v_num=3, train_loss_step=0.0148, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  94% 30/32 [00:04<00:00,  6.98it/s, v_num=3, train_loss_step=0.0219, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  97% 31/32 [00:04<00:00,  7.17it/s, v_num=3, train_loss_step=0.0219, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8:  97% 31/32 [00:04<00:00,  7.17it/s, v_num=3, train_loss_step=0.0227, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8: 100% 32/32 [00:04<00:00,  7.37it/s, v_num=3, train_loss_step=0.0227, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8: 100% 32/32 [00:04<00:00,  7.37it/s, v_num=3, train_loss_step=0.0359, val_loss=0.185, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "2024-07-31T20:30:51.803854328Z [1,0]<stdout>:\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:51.803903981Z [1,0]<stdout>:\n",
      "Validation:   0% 0/8 [00:00<?, ?it/s]        \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:51.813265664Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:51.822073147Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  12% 1/8 [00:00<00:00, 104.30it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:51.841077120Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  25% 2/8 [00:00<00:00, 108.54it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:51.850996312Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  38% 3/8 [00:00<00:00, 80.12it/s] \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:51.862777624Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  50% 4/8 [00:00<00:00, 84.48it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:51.871625393Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  62% 5/8 [00:00<00:00, 84.56it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:51.882029873Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  75% 6/8 [00:00<00:00, 88.26it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:51.892658705Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  88% 7/8 [00:00<00:00, 89.31it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:51.899485728Z [1,0]<stdout>:\n",
      "Validation DataLoader 0: 100% 8/8 [00:00<00:00, 89.89it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:58.593499373Z [1,0]<stdout>:\n",
      "                                                          \u001b[A[1,0]<stdout>:\n",
      "Epoch 8: 100% 32/32 [00:06<00:00,  4.61it/s, v_num=3, train_loss_step=0.0359, val_loss=0.192, train_loss_epoch=0.0244][1,0]<stdout>:\n",
      "Epoch 8: 100% 32/32 [00:06<00:00,  4.61it/s, v_num=3, train_loss_step=0.0359, val_loss=0.192, train_loss_epoch=0.024] [1,0]<stdout>:\n",
      "Epoch 8:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.0359, val_loss=0.192, train_loss_epoch=0.024]         [1,0]<stdout>:\n",
      "Epoch 9:   0% 0/32 [00:00<?, ?it/s, v_num=3, train_loss_step=0.0359, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:   3% 1/32 [00:02<01:19,  2.58s/it, v_num=3, train_loss_step=0.0359, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:   3% 1/32 [00:02<01:19,  2.58s/it, v_num=3, train_loss_step=0.0243, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:   6% 2/32 [00:02<00:39,  1.31s/it, v_num=3, train_loss_step=0.0243, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:   6% 2/32 [00:02<00:39,  1.31s/it, v_num=3, train_loss_step=0.0196, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:   9% 3/32 [00:02<00:25,  1.13it/s, v_num=3, train_loss_step=0.0196, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:   9% 3/32 [00:02<00:25,  1.13it/s, v_num=3, train_loss_step=0.0167, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  12% 4/32 [00:02<00:18,  1.49it/s, v_num=3, train_loss_step=0.0167, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  12% 4/32 [00:02<00:18,  1.49it/s, v_num=3, train_loss_step=0.0189, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  16% 5/32 [00:02<00:14,  1.84it/s, v_num=3, train_loss_step=0.0189, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  16% 5/32 [00:02<00:14,  1.84it/s, v_num=3, train_loss_step=0.0235, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  19% 6/32 [00:02<00:11,  2.18it/s, v_num=3, train_loss_step=0.0235, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  19% 6/32 [00:02<00:11,  2.18it/s, v_num=3, train_loss_step=0.0259, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  22% 7/32 [00:02<00:09,  2.52it/s, v_num=3, train_loss_step=0.0259, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  22% 7/32 [00:02<00:09,  2.52it/s, v_num=3, train_loss_step=0.0232, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  25% 8/32 [00:02<00:08,  2.85it/s, v_num=3, train_loss_step=0.0232, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  25% 8/32 [00:02<00:08,  2.85it/s, v_num=3, train_loss_step=0.0231, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  28% 9/32 [00:02<00:07,  3.17it/s, v_num=3, train_loss_step=0.0231, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  28% 9/32 [00:02<00:07,  3.17it/s, v_num=3, train_loss_step=0.0168, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  31% 10/32 [00:02<00:06,  3.49it/s, v_num=3, train_loss_step=0.0168, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  31% 10/32 [00:02<00:06,  3.49it/s, v_num=3, train_loss_step=0.0258, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  34% 11/32 [00:02<00:05,  3.80it/s, v_num=3, train_loss_step=0.0258, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  34% 11/32 [00:02<00:05,  3.80it/s, v_num=3, train_loss_step=0.0137, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  38% 12/32 [00:02<00:04,  4.11it/s, v_num=3, train_loss_step=0.0137, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  38% 12/32 [00:02<00:04,  4.09it/s, v_num=3, train_loss_step=0.0256, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  41% 13/32 [00:03<00:04,  3.88it/s, v_num=3, train_loss_step=0.0256, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  41% 13/32 [00:03<00:04,  3.88it/s, v_num=3, train_loss_step=0.0271, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  44% 14/32 [00:03<00:04,  4.14it/s, v_num=3, train_loss_step=0.0271, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  44% 14/32 [00:03<00:04,  4.14it/s, v_num=3, train_loss_step=0.0383, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  47% 15/32 [00:03<00:03,  4.40it/s, v_num=3, train_loss_step=0.0383, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  47% 15/32 [00:03<00:03,  4.40it/s, v_num=3, train_loss_step=0.0307, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  50% 16/32 [00:03<00:03,  4.66it/s, v_num=3, train_loss_step=0.0307, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  50% 16/32 [00:03<00:03,  4.65it/s, v_num=3, train_loss_step=0.0157, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  53% 17/32 [00:03<00:03,  4.91it/s, v_num=3, train_loss_step=0.0157, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  53% 17/32 [00:03<00:03,  4.90it/s, v_num=3, train_loss_step=0.0241, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  56% 18/32 [00:03<00:02,  5.15it/s, v_num=3, train_loss_step=0.0241, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  56% 18/32 [00:03<00:02,  5.15it/s, v_num=3, train_loss_step=0.0158, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  59% 19/32 [00:03<00:02,  5.40it/s, v_num=3, train_loss_step=0.0158, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  59% 19/32 [00:03<00:02,  5.39it/s, v_num=3, train_loss_step=0.0408, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  62% 20/32 [00:03<00:02,  5.64it/s, v_num=3, train_loss_step=0.0408, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  62% 20/32 [00:03<00:02,  5.63it/s, v_num=3, train_loss_step=0.0237, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  66% 21/32 [00:03<00:01,  5.87it/s, v_num=3, train_loss_step=0.0237, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  66% 21/32 [00:03<00:01,  5.87it/s, v_num=3, train_loss_step=0.0134, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  69% 22/32 [00:03<00:01,  6.10it/s, v_num=3, train_loss_step=0.0134, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  69% 22/32 [00:03<00:01,  6.10it/s, v_num=3, train_loss_step=0.0173, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  72% 23/32 [00:03<00:01,  6.33it/s, v_num=3, train_loss_step=0.0173, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  72% 23/32 [00:03<00:01,  6.33it/s, v_num=3, train_loss_step=0.0392, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  75% 24/32 [00:03<00:01,  6.56it/s, v_num=3, train_loss_step=0.0392, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  75% 24/32 [00:03<00:01,  6.55it/s, v_num=3, train_loss_step=0.0382, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  78% 25/32 [00:04<00:01,  6.14it/s, v_num=3, train_loss_step=0.0382, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  78% 25/32 [00:04<00:01,  6.14it/s, v_num=3, train_loss_step=0.0192, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  81% 26/32 [00:04<00:00,  6.35it/s, v_num=3, train_loss_step=0.0192, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  81% 26/32 [00:04<00:00,  6.34it/s, v_num=3, train_loss_step=0.0238, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  84% 27/32 [00:04<00:00,  6.55it/s, v_num=3, train_loss_step=0.0238, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  84% 27/32 [00:04<00:00,  6.55it/s, v_num=3, train_loss_step=0.0247, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  88% 28/32 [00:04<00:00,  6.75it/s, v_num=3, train_loss_step=0.0247, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  88% 28/32 [00:04<00:00,  6.75it/s, v_num=3, train_loss_step=0.0335, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  91% 29/32 [00:04<00:00,  6.95it/s, v_num=3, train_loss_step=0.0335, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  91% 29/32 [00:04<00:00,  6.94it/s, v_num=3, train_loss_step=0.0356, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  94% 30/32 [00:04<00:00,  7.15it/s, v_num=3, train_loss_step=0.0356, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  94% 30/32 [00:04<00:00,  7.14it/s, v_num=3, train_loss_step=0.0185, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  97% 31/32 [00:04<00:00,  7.34it/s, v_num=3, train_loss_step=0.0185, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9:  97% 31/32 [00:04<00:00,  7.33it/s, v_num=3, train_loss_step=0.0445, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9: 100% 32/32 [00:04<00:00,  7.53it/s, v_num=3, train_loss_step=0.0445, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9: 100% 32/32 [00:04<00:00,  7.53it/s, v_num=3, train_loss_step=0.0515, val_loss=0.192, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "2024-07-31T20:30:59.315513327Z [1,0]<stdout>:\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:59.315602357Z [1,0]<stdout>:\n",
      "Validation:   0% 0/8 [00:00<?, ?it/s]        \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:59.324217203Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:59.334159673Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  12% 1/8 [00:00<00:00, 113.15it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:59.344242655Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  25% 2/8 [00:00<00:00, 106.47it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:59.354735177Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  38% 3/8 [00:00<00:00, 103.92it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:59.365099170Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  50% 4/8 [00:00<00:00, 101.62it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:59.375486617Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  62% 5/8 [00:00<00:00, 100.56it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:59.385859947Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  75% 6/8 [00:00<00:00, 99.82it/s] \u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:59.396126344Z [1,0]<stdout>:\n",
      "Validation DataLoader 0:  88% 7/8 [00:00<00:00, 99.31it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:30:59.402762256Z [1,0]<stdout>:\n",
      "Validation DataLoader 0: 100% 8/8 [00:00<00:00, 99.07it/s]\u001b[A[1,0]<stdout>:\n",
      "2024-07-31T20:31:00.010819546Z [1,0]<stderr>:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "2024-07-31T20:31:00.011027069Z [1,0]<stdout>:\n",
      "                                                          [1,0]<stdout>:\u001b[A[1,0]<stdout>:\n",
      "Epoch 9: 100% 32/32 [00:06<00:00,  4.67it/s, v_num=3, train_loss_step=0.0515, val_loss=0.190, train_loss_epoch=0.024][1,0]<stdout>:\n",
      "Epoch 9: 100% 32/32 [00:06<00:00,  4.66it/s, v_num=3, train_loss_step=0.0515, val_loss=0.190, train_loss_epoch=0.0254][1,0]<stdout>:\n",
      "Epoch 9: 100% 32/32 [00:07<00:00,  4.29it/s, v_num=3, train_loss_step=0.0515, val_loss=0.190, train_loss_epoch=0.0254]\n",
      "2024-07-31T20:31:00.267222967Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:533 [0] NCCL INFO [Service thread] Connection closed by localRank 0\n",
      "2024-07-31T20:31:00.781111945Z [1,0]<stdout>:lm-mpi-job-67327a4b-7f80-4b1e-ad18-ca4a4da9b6aa-mpimaster-0:189:189 [0] NCCL INFO comm 0xfcd99a0 rank 0 nranks 1 cudaDev 0 busId bf000 - Abort COMPLETE\n"
     ]
    }
   ],
   "source": [
    "job_run.logs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-hugging_example]",
   "language": "python",
   "name": "conda-env-.mlspace-hugging_example-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
