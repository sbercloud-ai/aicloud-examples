# Пример настройки и обучения языковой модели (LLM)

В этом примере рассмотрена работа с LLM (Large Language Model) методами LoRA и PEFT.
Используется библиотека transformers от Hugging Face.

В [файле Jupyter Notebook](llm-example.ipynb) показаны установка зависимостей, загрузка и настройка модели, обучение и генерация текста. Его можно использовать и модифицировать под собственные задачи.

В [пользовательской документации по LLM](https://cloud.ru/docs/aicloud/mlspace/concepts/tutorials/llm/tutorials__guides__llm_install.html) даны концептуальные понятия и подробные описания каждого этапа: предпосылки и объяснения работы методов и подходов.
