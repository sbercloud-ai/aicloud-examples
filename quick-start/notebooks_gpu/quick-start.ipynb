{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Jupyter Notebook для тестирования задач в регионах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pathlib\n",
    "import client_lib # импортируем библиотеку для работы с ML Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Устанавливаем переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = str(pathlib.Path().absolute())\n",
    "print(f\"Working dir: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Запуск задачи обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс client_lib.Job() позволяет запускать распределённые задачи в регионе. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обязательные параметры для запуска задачи обучения:\n",
    "- **script** – путь к запускаемому скрипту\n",
    "- **base_image** – базовый образ, в котором будет исполняться скрипт обучения модели\n",
    "- **instance_type** – конфигурация вычислительных ресурсов, используемых для решения задач\n",
    "\n",
    "Подробное описание параметров можно найти в документации по [ссылке](https://cloud.ru/ru/docs/aicloud/mlspace/concepts/client-lib__job.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию задачи запускаются в регионе Christofari.V100. Для того, чтобы запустить задачу в другом регионе, необходимо указать регион в параметре region.\n",
    "\n",
    "Доступные регионы и их обозначения в client_lib:\n",
    "\n",
    "- Christofari.V100 – DGX2-MT\n",
    "- Christofari.A100 – A100-MT\n",
    "- Cloud.Region.A100 (GPU Tesla A100) – SR002-MT\n",
    "- Cloud.Region.HP1 – SR003\n",
    "- Cloud.Region.HP- DGX2-MT – SR006\n",
    "\n",
    "Для примера запустим задачу в регионе Cloud.Region.A100 (SR002-MT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для масштабирования задачи доступны следующие параметры:\n",
    "\n",
    "- **n_workers** – количество рабочих узлов региона, на котором будет исполняться скрипт\n",
    "- **instance_type** – конфигурация вычислительных ресурсов, используемых для решения задач\n",
    "\n",
    "Для выбора значения параметра instance_type воспользуемся методом get_instance_types(). Подробнее об использовании метода в [документации](https://cloud.ru/ru/docs/aicloud/mlspace/concepts/client-lib__common-methods.html#client-lib-get-instance-types)\n",
    "\n",
    "Выведем доступные значения instance_type для региона SR002-MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client_lib.get_instance_types(client_lib.ClusterType.MT).query('region == \"SR002-MT\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера запустим задачу на 1 воркере с 1 ГПУ.\n",
    "\n",
    "Сохраним в переменные название региона, instanse_type и образы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"SR002-MT\"\n",
    "INSTANCE_TYPE = \"a100.1gpu.40\"\n",
    "N_WORKERS = 1\n",
    "BASE_IMAGE = \"cr.ai.cloud.ru/aicloud-base-images/cuda12.1-torch2-py39:0.0.36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = client_lib.Job(\n",
    "    base_image=BASE_IMAGE,\n",
    "    script=f\"{BASE_DIR}/train_distributed_example-torch2.py\",\n",
    "    region=REGION,\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    n_workers=N_WORKERS,\n",
    "    type=\"pytorch2\",\n",
    "    processes_per_worker=1,\n",
    "    job_desc=\"pytorch2 | client_lib | use_env=False | torch2\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим задачу методом submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения статуса задачи воспользуемся методом status()\n",
    "\n",
    "Возможные статусы задачи \n",
    "\n",
    "- «Pending» - Задача находится в очереди на выделение ресурсов, которые нужны для ее исполнения.\n",
    "\n",
    "- «Running» - Задача обучения выполняется.\n",
    "\n",
    "- «Completed» или «Succeeded» – Задача обучения завершилась.\n",
    "\n",
    "- «Completing» – Задача обучения завершается.\n",
    "\n",
    "- «Failed» – Задача обучения завершилась с ошибкой, рекомендуется проверить логи задачи.\n",
    "\n",
    "- «Deleted» или «Terminated» – Задача обучения удалена.\n",
    "\n",
    "- «Stopped» или «Aborted» – Задача обучения остановлена.\n",
    "\n",
    "- «Terminating» – Задача обучения останавливается. Освобождаются ресурсы, задача и поды удаляются.\n",
    "\n",
    "- «Aborting» – Задача обучения останавливается. Освобождаются ресурсы, удаляются только поды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для просмотра логов задачи можно вызвать метод logs()\n",
    "\n",
    "Логи будут доступны после запуска задачи(перехода в статус Running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача завершиться автоматически после выполнения скрипта. Если требуется прервать выполнение задачи, можно воспользоваться методом kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Передача переменных окружения и флагов при запуске задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В параметре flags можно передать флаги, с которыми необходимо запустить скрипт. Параметр принимает словарь в формате {\"<флаг>\": \"<значение>\"}\n",
    "\n",
    "Пример задания параметра flags:\n",
    "\n",
    "```\n",
    "flags={\n",
    "    \"foo\": \"foo_value\", \n",
    "    \"bar\": \"bar_value\",\n",
    "}\n",
    "```\n",
    "Скрипт будет запущен с параметрами ```<your_script> --batch_size=512 --model=\"mymodel50\" --xla=False\n",
    "\n",
    "\n",
    "\n",
    "Переменные окружения можно передать в параметре env_variables. Параметр принимает словарь в формате {\"<название переменной>\": \"<значение>\"}\n",
    "\n",
    "\n",
    "Пример задания параметра env_variables:\n",
    "\n",
    "```\n",
    "env_variables={\n",
    "    \"BAZ\": \"baz_value\",\n",
    "    \"QUUX\": \"quux_value\",\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = client_lib.Job(\n",
    "    base_image=BASE_IMAGE,\n",
    "    script=f\"{BASE_DIR}/env_variables_flags_test.py\",\n",
    "    region=REGION,\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    n_workers=1,\n",
    "    type=\"pytorch2\",\n",
    "    processes_per_worker=1,\n",
    "    flags={\n",
    "        \"foo\": \"foo_value\", \n",
    "        \"bar\": \"bar_value\",\n",
    "    },\n",
    "    env_variables={\n",
    "        \"BAZ\": \"baz_value\",\n",
    "        \"QUUX\": \"quux_value\",\n",
    "    },\n",
    "    job_desc=\"testing flags and env_variables\",\n",
    "    pytorch_use_env=True,\n",
    "    in_communal_cluster=True,\n",
    ")\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим в логах, что флаги и переменные окружения передались при запуске задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение к задаче по SSH\n",
    "\n",
    "**Подключение доступно в Jupyter server с образами версии 0.0.95 и выше**\n",
    "\n",
    "Для примера запустим бесконечную задачу. Чтобы задача не завершилась, укажем ```script=\"sleep infinity\"``` и ```type=\"binary\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = client_lib.Job(\n",
    "    base_image=BASE_IMAGE,\n",
    "    script=\"sleep infinity\", # передаём sleep infinity для того, чтобы задача не завершалась\n",
    "    region=REGION,\n",
    "    instance_type=\"a100plus.1gpu.80vG.12C.96G\",\n",
    "    n_workers=1,\n",
    "    type=\"binary\", # передаём тип binary для запуска shell-скриптов\n",
    "    processes_per_worker=1,\n",
    "    job_desc=\"sleep infinity\",\n",
    "    in_communal_cluster=True\n",
    ")\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подключения нам нужно будет имя задачи, получим его с помощью атрибута job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключится можно к задаче в статусе \"Running\"\n",
    "\n",
    "Для подключения можно использовать команду mlspace ssh. Есть 2 варианта подключения – по хосту и local rank.\n",
    "\n",
    "#### Подключение по хосту\n",
    "Для подключения по хосту необходимо выполнить в терминале команду ```mlspace ssh by-host HOST```\n",
    "\n",
    "В качестве хоста необходимо указать \n",
    "- ```lm-mpi-job-<uuid_v4>-mpimaster-0``` – для подключения к мастеру \n",
    "- ```lm-mpi-job-<uuid_v4>-mpiworker-<number>``` – для подключения к воркеру                   \n",
    "                                                                                                                              \n",
    "Пример использования: ```mlspace ssh by-host lm-mpi-job-842ec184-4610-420e-9ca8-8198ddf9167e-mpiworker-1```                                                       \n",
    "\n",
    "#### Подключение по local rank\n",
    "Для подключения по local rank необходимо выполнить в терминале команду ```mlspace ssh by-rank --rank <number> JOB_NAME```\n",
    "\n",
    "в параметр --rank передать положительное число worker_(number). \n",
    "Значения:\n",
    "- rank 0 - mpimaster-0\n",
    "- rank 1 - mpiworker-0\n",
    "- rank N - mpiworker-{N + 1}\n",
    "одключение через ssh к заданому worker_(number).                                                                                                             \n",
    " Пример использования:mlspace ssh by-rank lm-mpi-job-842ec184-4610-420e-9ca8-8198ddf9167e --rank 1                                                             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно** после проверки подключения необходимо завершить задачу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_lib.jobs(region=f\"{REGION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. [Optional] - Сохранение промежуточных результатов обучения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в процессе обучения модели пользователь сохраняет промежуточные результаты (checkpoints) обучения, они попадают в папку `./logs`. Их можно скачать через веб-интерфейс Jupyter-ноутбука или скопировать из локально доступной файловой системы в хранилище S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выгрузка результатов обучения модели с NFS на S3\n",
    "\n",
    "Для переноса файлов между NFS и S3 можно использовать [методы копирования client_lib](https://aicdoc-613-add-in-faq-from--e42921f5.docs.sbercloud.dev/aicloud/mlspace/concepts/client-lib__copy-to-nfs.html#id1) или правила переноса [Data Transfer Service](https://cloud.ru/ru/docs/aicloud/mlspace/concepts/guides/guides__dc/data-catalog__data-processing__create-transfer-rule.html)\n",
    "\n",
    "Рассмотрим копирование файлов из NFS на S3 воркспейса с помощью метода ```copy_from_nfs()```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path = str(pathlib.Path().absolute().relative_to(pathlib.Path().absolute().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_lib.copy_from_nfs(\n",
    "    source_path=f\"{relative_path}/logs/\", # укажем путь к папке logs без /home/jovyam \n",
    "    from_region=client_lib.RegionEnum.SR002_MT, # укажем регион, в нашем случае SR002-MT\n",
    "    destination_path=\"quck-start\" # укажем место назначения переноса\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помошью ID посмотрим логи переноса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_lib.get_transfer_data_logs(\"3ebe26ec-1d6f-4797-926e-642f1fcbe12f\") # id переноса берём из вывода предыдущей ячейки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате мы перенесли папку logs в S3 воркспейса в папку quick-start.\n",
    "\n",
    "Проверить наличие файлов на S3 можно перейдя в раздел \"Data Catalog\" -> \"Объектное Хранилище\" и выбрав бакет воркспейса с доступом \"Public\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. [Optional] - Собираем кастомный образ с нужными библиотеками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Посмотреть содержимое файла requirements.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Запуск сборки кастомного образа с необходимыми библиотеками\n",
    "\n",
    "После выполнения этой задачи собранный образ должен оказаться в docker registry\n",
    "\n",
    "**Важно! Для сборки кастомного образа файл requirements.txt должен быть загружен на NFS региона Christofari.V100**\n",
    "\n",
    "\n",
    "Список базовых образов, которые нужно указать в зависимости от региона в параметре \"from_image\": [Образы для задач обучения](https://cloud.ru/ru/docs/aicloud/mlspace/concepts/environments__basic-images-list__jobs.html)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также есть возможность собрать кастомный образ локально с помощью Docker. Инструкция доступна по [ссылке](https://cloud.ru/ru/docs/aicloud/mlspace/concepts/guides/guides__mt/environments__docker-registry__custom__job__image.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = client_lib.ImageBuildJob(\n",
    "    from_image=BASE_IMAGE,  # базовый образ для задач обучения\n",
    "    requirements_file=f\"{BASE_DIR}/requirements.txt\", # файл с зависимостями для кастомного образа\n",
    ")\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.new_image  # идентификатор кастомного образа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job.logs()  # просмотр логов сборки образа в интерактивном режиме"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
